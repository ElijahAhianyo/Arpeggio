{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Arpeggio is recursive descent parser with backtracking and memoization (a.k.a. pacrat parser). Arpeggio grammars are based on PEG formalism . Arpeggio's main use is a foundation for a tool-chain for DSL development but it can be used for all sort of general purpose parsing. For more information on PEG and packrat parsers see this page . For a higher level library for building DSLs take a look at textX . It builds on top of Arpeggio and makes language parser implementation a lot easier. See Getting started in the User Guide menu to get you going or read some of the tutorials. Features \u00b6 Using Parsing Expression Grammar and packrat parsing - unambiguous grammars, unlimited lookahead, linear time. Works as grammar interpreter - no code is generated. Multiple syntaxes for grammar definition ( Python , peg, cleanpeg , make your own) Case sensitive/insensitive parsing Whitespace handling control Keyword handling Support for comments Newline termination for Repetition (available only in Python syntax) Parse tree navigation Visitors for semantic analysis Extensive error reporting Good support for debugging and visualization Good test coverage Beautiful mkdocs documentation - you are reading it Python versions \u00b6 Arpeggio works with Python 2.7, 3.4+. Other versions might work but are not tested. Open-source projects using Arpeggio \u00b6 textX - Meta-language for building Domain-Specific Languages in Python (and all projects using textX) whatami - Unobtrusive object self-identification for Python ( parsers module) ithkuil - A Python package providing tools for analysing texts in the Ithkuil constructed language. Why is it called arpeggio? \u00b6 In music, arpeggio is playing the chord notes one by one in sequence. I came up with the name by thinking that parsing is very similar to arpeggios in music. You take tokens one by one from an input and make sense out of it \u2013 make a chord! Well, if you don't buy this maybe it is time to tell you the truth. I searched the dictionary for the words that contain PEG acronym and the word arpeggio was at the top of the list ;) Citing Arpeggio \u00b6 If you use Arpeggio please cite this paper: Dejanovi\u0107 I., Milosavljevi\u0107 G., Vaderna R.: Arpeggio: A flexible PEG parser for Python, Knowledge-Based Systems, 2016, 95, 71 - 74, doi:10.1016/j.knosys.2015.12.004","title":"Home"},{"location":"#features","text":"Using Parsing Expression Grammar and packrat parsing - unambiguous grammars, unlimited lookahead, linear time. Works as grammar interpreter - no code is generated. Multiple syntaxes for grammar definition ( Python , peg, cleanpeg , make your own) Case sensitive/insensitive parsing Whitespace handling control Keyword handling Support for comments Newline termination for Repetition (available only in Python syntax) Parse tree navigation Visitors for semantic analysis Extensive error reporting Good support for debugging and visualization Good test coverage Beautiful mkdocs documentation - you are reading it","title":"Features"},{"location":"#python-versions","text":"Arpeggio works with Python 2.7, 3.4+. Other versions might work but are not tested.","title":"Python versions"},{"location":"#open-source-projects-using-arpeggio","text":"textX - Meta-language for building Domain-Specific Languages in Python (and all projects using textX) whatami - Unobtrusive object self-identification for Python ( parsers module) ithkuil - A Python package providing tools for analysing texts in the Ithkuil constructed language.","title":"Open-source projects using Arpeggio"},{"location":"#why-is-it-called-arpeggio","text":"In music, arpeggio is playing the chord notes one by one in sequence. I came up with the name by thinking that parsing is very similar to arpeggios in music. You take tokens one by one from an input and make sense out of it \u2013 make a chord! Well, if you don't buy this maybe it is time to tell you the truth. I searched the dictionary for the words that contain PEG acronym and the word arpeggio was at the top of the list ;)","title":"Why is it called arpeggio?"},{"location":"#citing-arpeggio","text":"If you use Arpeggio please cite this paper: Dejanovi\u0107 I., Milosavljevi\u0107 G., Vaderna R.: Arpeggio: A flexible PEG parser for Python, Knowledge-Based Systems, 2016, 95, 71 - 74, doi:10.1016/j.knosys.2015.12.004","title":"Citing Arpeggio"},{"location":"configuration/","text":"Parser configuration \u00b6 This section describes how to alter parser default behaviour. There are some aspect of parsing that can be configured using parser and/or ParsingExpression parameters. Arpeggio has some sane default behaviour but gives the user possibility to alter it. This section describes various parser parameters. Case insensitive parsing \u00b6 By default Arpeggio is case sensitive. If you wish to do case insensitive parsing set parser parameter ignore_case to True . parser = ParserPython(calc, ignore_case=True) White-space handling \u00b6 Arpeggio by default skips white-spaces. You can change this behaviour with the parameter skipws given to parser constructor. parser = ParserPython(calc, skipws=False) You can also change what is considered a whitespace by Arpeggio using the ws parameter. It is a plain string that consists of white-space characters. By default it is set to \"\\t\\n\\r \" . For example, to prevent a newline to be treated as whitespace you could write: parser = ParserPython(calc, ws='\\t\\r ') Note These parameters can be used on the Sequence level so one could write grammar like this: def grammar(): return Sequence(\"one\", \"two\", \"three\", skipws=False), \"four\" parser = ParserPython(grammar) pt = parser.parse(\"onetwothree four\") Keyword handling \u00b6 By setting a autokwd parameter to True a word boundary match for keyword-like matches will be performed. This parameter is disabled by default. def grammar(): return \"one\", \"two\", \"three\" parser = ParserPython(grammar, autokwd=True) # If autokwd is enabled this should parse without error. parser.parse(\"one two three\") # But this will not parse as the match is done using word boundaries # so this is considered a one word. parser.parse(\"onetwothree\") Comment handling \u00b6 Support for comments in your language can be specified as another set of grammar rules. See simple.py example . Parser is constructed using two parameters. parser = ParserPython(simpleLanguage, comment) First parameter is the root rule of main parse model while the second is a rule for comments. During parsing comment parse trees are kept in the separate list thus comments will not show in the main parse tree. Parse tree reduction \u00b6 Non-terminals are by default created for each rule. Sometimes it can result in trees of great depth. You can alter this behaviour setting reduce_tree parameter to True . parser = ParserPython(calc, reduce_tree=True) In this configuration non-terminals a with single child will be removed from the parse tree. For example, calc parse tree above will look like this: Notice the removal of each non-terminal with a single child. Warning Be aware that semantic analysis operates on nodes of finished parse tree. Therefore, if you use tree reduction , visitor methods will not get called for the removed nodes. Newline termination for Repetitions \u00b6 By default Repetition parsing expressions (i.e. ZeroOrMore and OneOrMore ) will obey skipws and ws settings but there are situations where repetitions should not pass the end of the current line. For this feature eolterm parameter is introduced which can be set on a repetition and will ensure that it terminates before entering a new line. def grammar(): return first, second def first(): return ZeroOrMore([\"a\", \"b\"], eolterm=True) def second(): return \"a\" # first rule should match only first line # so that second rule will match \"a\" on the new line input = \"\"\"a a b a b b a\"\"\" parser = ParserPython(grammar) result = parser.parse(input) Separator for Repetitions \u00b6 It is possible to specify parsing expression that will be used in between each two matches in repetitions. For example: def grammar(): return ZeroOrMore([\"a\", \"b\"], sep=\",\") # Commas will be treated as separators between elements input = \"a , b, b, a\" parser = ParserPython(grammar) result = parser.parse(input) sep can be any valid parsing expression. Memoization (a.k.a. packrat parsing) \u00b6 This technique is based on memoizing result on each parsing expression rule. For some grammars with a lot of backtracking this can yield a significant speed increase at the expense of some memory used for the memoization cache. Starting with Arpeggio 1.5 this feature is disabled by default. If you think that parsing is slow, try to enable memoization by setting memoization parameter to True during parser instantiation. parser = ParserPython(grammar, memoization=True)","title":"Parser configuration"},{"location":"configuration/#parser-configuration","text":"This section describes how to alter parser default behaviour. There are some aspect of parsing that can be configured using parser and/or ParsingExpression parameters. Arpeggio has some sane default behaviour but gives the user possibility to alter it. This section describes various parser parameters.","title":"Parser configuration"},{"location":"configuration/#case-insensitive-parsing","text":"By default Arpeggio is case sensitive. If you wish to do case insensitive parsing set parser parameter ignore_case to True . parser = ParserPython(calc, ignore_case=True)","title":"Case insensitive parsing"},{"location":"configuration/#white-space-handling","text":"Arpeggio by default skips white-spaces. You can change this behaviour with the parameter skipws given to parser constructor. parser = ParserPython(calc, skipws=False) You can also change what is considered a whitespace by Arpeggio using the ws parameter. It is a plain string that consists of white-space characters. By default it is set to \"\\t\\n\\r \" . For example, to prevent a newline to be treated as whitespace you could write: parser = ParserPython(calc, ws='\\t\\r ') Note These parameters can be used on the Sequence level so one could write grammar like this: def grammar(): return Sequence(\"one\", \"two\", \"three\", skipws=False), \"four\" parser = ParserPython(grammar) pt = parser.parse(\"onetwothree four\")","title":"White-space handling"},{"location":"configuration/#keyword-handling","text":"By setting a autokwd parameter to True a word boundary match for keyword-like matches will be performed. This parameter is disabled by default. def grammar(): return \"one\", \"two\", \"three\" parser = ParserPython(grammar, autokwd=True) # If autokwd is enabled this should parse without error. parser.parse(\"one two three\") # But this will not parse as the match is done using word boundaries # so this is considered a one word. parser.parse(\"onetwothree\")","title":"Keyword handling"},{"location":"configuration/#comment-handling","text":"Support for comments in your language can be specified as another set of grammar rules. See simple.py example . Parser is constructed using two parameters. parser = ParserPython(simpleLanguage, comment) First parameter is the root rule of main parse model while the second is a rule for comments. During parsing comment parse trees are kept in the separate list thus comments will not show in the main parse tree.","title":"Comment handling"},{"location":"configuration/#parse-tree-reduction","text":"Non-terminals are by default created for each rule. Sometimes it can result in trees of great depth. You can alter this behaviour setting reduce_tree parameter to True . parser = ParserPython(calc, reduce_tree=True) In this configuration non-terminals a with single child will be removed from the parse tree. For example, calc parse tree above will look like this: Notice the removal of each non-terminal with a single child. Warning Be aware that semantic analysis operates on nodes of finished parse tree. Therefore, if you use tree reduction , visitor methods will not get called for the removed nodes.","title":"Parse tree reduction"},{"location":"configuration/#newline-termination-for-repetitions","text":"By default Repetition parsing expressions (i.e. ZeroOrMore and OneOrMore ) will obey skipws and ws settings but there are situations where repetitions should not pass the end of the current line. For this feature eolterm parameter is introduced which can be set on a repetition and will ensure that it terminates before entering a new line. def grammar(): return first, second def first(): return ZeroOrMore([\"a\", \"b\"], eolterm=True) def second(): return \"a\" # first rule should match only first line # so that second rule will match \"a\" on the new line input = \"\"\"a a b a b b a\"\"\" parser = ParserPython(grammar) result = parser.parse(input)","title":"Newline termination for Repetitions"},{"location":"configuration/#separator-for-repetitions","text":"It is possible to specify parsing expression that will be used in between each two matches in repetitions. For example: def grammar(): return ZeroOrMore([\"a\", \"b\"], sep=\",\") # Commas will be treated as separators between elements input = \"a , b, b, a\" parser = ParserPython(grammar) result = parser.parse(input) sep can be any valid parsing expression.","title":"Separator for Repetitions"},{"location":"configuration/#memoization-aka-packrat-parsing","text":"This technique is based on memoizing result on each parsing expression rule. For some grammars with a lot of backtracking this can yield a significant speed increase at the expense of some memory used for the memoization cache. Starting with Arpeggio 1.5 this feature is disabled by default. If you think that parsing is slow, try to enable memoization by setting memoization parameter to True during parser instantiation. parser = ParserPython(grammar, memoization=True)","title":"Memoization (a.k.a. packrat parsing)"},{"location":"debugging/","text":"Debugging \u00b6 When the stuff goes wrong you will want to debug your parser. Parser debug mode \u00b6 During grammar design you can make syntax and semantic errors. Arpeggio will report any syntax error with all the necessary information whether you are building parser from python expressions or from a textual PEG notation. For semantic error you have a debugging mode of operation which is entered by setting debug parameter to True in the parser construction call. parser = ParserPython(calc, debug=True) When Arpeggio runs in debug mode it will print a detailed information of what it is doing. >> Entering rule calc=Sequence at position 0 => *-(4-1)*5+( >> Entering rule OneOrMore in calc at position 0 => *-(4-1)*5+( >> Entering rule expression=Sequence in calc at position 0 => *-(4-1)*5+( >> Entering rule term=Sequence in expression at position 0 => *-(4-1)*5+( >> Entering rule factor=Sequence in term at position 0 => *-(4-1)*5+( >> Entering rule Optional in factor at position 0 => *-(4-1)*5+( >> Entering rule OrderedChoice in factor at position 0 => *-(4-1)*5+( >> Match rule StrMatch(+) in factor at position 0 => *-(4-1)*5+( -- No match '+' at 0 => '*-*(4-1)*5+(' >> Match rule StrMatch(-) in factor at position 0 => *-(4-1)*5+( ++ Match '-' at 0 => '*-*(4-1)*5+(' << Leaving rule OrderedChoice << Leaving rule Optional >> Entering rule OrderedChoice in factor at position 1 => -*(4-1)*5+(2 Visualization \u00b6 Furthermore, while running in debug mode, a dot file (a graph description file format from GraphViz software package ) representing the parser model will be created if the parser model is constructed without errors. This dot file can be rendered as image using one of available dot viewer software or transformed to an image using dot tool GraphViz software. $ dot -Tpng -O calc_parser_model.dot After this command you will get calc_parser_model.dot.png file which can be opened in any png image viewer. This is how it looks like: Each node in this graph is a parsing expression. Nodes are labeled by the type name of the parsing expression. If node represents the rule from the grammar, the label is of the form <rule_name>=<PEG type> where rule_name is the name of the grammar rule. The edges connect children expressions. The labels on the edges represent the order in which the graph will be traversed during parsing. Furthermore, if you parse some input while the parser is in debug mode, the parse tree dot file will be generated also. parse_tree = parser.parse(\"-(4-1)*5+(2+4.67)+5.89/(.2+7)\") This dot file can also be converted to png with the command: $ dot -Tpng -O calc_parse_tree.dot Which produces png image given bellow. You can also explicitly render your parser model or parse tree to dot file even if the parser is not in the debug mode. For parser model this is achieved with the following Python code: from arpeggio.export import PMDOTExporter PMDOTExporter().exportFile(parser.parser_model, \"my_parser_model.dot\") For parse tree it is achieved with: from arpeggio.export import PTDOTExporter PTDOTExporter().exportFile(parse_tree, \"my_parse_tree.dot\") To get e.g. png images from dot files do as usual: $ dot -Tpng -O *.dot Note All tree images in this docs are rendered using Arpeggio's visualization and dot tool from the GraphViz software.","title":"Debugging"},{"location":"debugging/#debugging","text":"When the stuff goes wrong you will want to debug your parser.","title":"Debugging"},{"location":"debugging/#parser-debug-mode","text":"During grammar design you can make syntax and semantic errors. Arpeggio will report any syntax error with all the necessary information whether you are building parser from python expressions or from a textual PEG notation. For semantic error you have a debugging mode of operation which is entered by setting debug parameter to True in the parser construction call. parser = ParserPython(calc, debug=True) When Arpeggio runs in debug mode it will print a detailed information of what it is doing. >> Entering rule calc=Sequence at position 0 => *-(4-1)*5+( >> Entering rule OneOrMore in calc at position 0 => *-(4-1)*5+( >> Entering rule expression=Sequence in calc at position 0 => *-(4-1)*5+( >> Entering rule term=Sequence in expression at position 0 => *-(4-1)*5+( >> Entering rule factor=Sequence in term at position 0 => *-(4-1)*5+( >> Entering rule Optional in factor at position 0 => *-(4-1)*5+( >> Entering rule OrderedChoice in factor at position 0 => *-(4-1)*5+( >> Match rule StrMatch(+) in factor at position 0 => *-(4-1)*5+( -- No match '+' at 0 => '*-*(4-1)*5+(' >> Match rule StrMatch(-) in factor at position 0 => *-(4-1)*5+( ++ Match '-' at 0 => '*-*(4-1)*5+(' << Leaving rule OrderedChoice << Leaving rule Optional >> Entering rule OrderedChoice in factor at position 1 => -*(4-1)*5+(2","title":"Parser debug mode"},{"location":"debugging/#visualization","text":"Furthermore, while running in debug mode, a dot file (a graph description file format from GraphViz software package ) representing the parser model will be created if the parser model is constructed without errors. This dot file can be rendered as image using one of available dot viewer software or transformed to an image using dot tool GraphViz software. $ dot -Tpng -O calc_parser_model.dot After this command you will get calc_parser_model.dot.png file which can be opened in any png image viewer. This is how it looks like: Each node in this graph is a parsing expression. Nodes are labeled by the type name of the parsing expression. If node represents the rule from the grammar, the label is of the form <rule_name>=<PEG type> where rule_name is the name of the grammar rule. The edges connect children expressions. The labels on the edges represent the order in which the graph will be traversed during parsing. Furthermore, if you parse some input while the parser is in debug mode, the parse tree dot file will be generated also. parse_tree = parser.parse(\"-(4-1)*5+(2+4.67)+5.89/(.2+7)\") This dot file can also be converted to png with the command: $ dot -Tpng -O calc_parse_tree.dot Which produces png image given bellow. You can also explicitly render your parser model or parse tree to dot file even if the parser is not in the debug mode. For parser model this is achieved with the following Python code: from arpeggio.export import PMDOTExporter PMDOTExporter().exportFile(parser.parser_model, \"my_parser_model.dot\") For parse tree it is achieved with: from arpeggio.export import PTDOTExporter PTDOTExporter().exportFile(parse_tree, \"my_parse_tree.dot\") To get e.g. png images from dot files do as usual: $ dot -Tpng -O *.dot Note All tree images in this docs are rendered using Arpeggio's visualization and dot tool from the GraphViz software.","title":"Visualization"},{"location":"getting_started/","text":"Getting started \u00b6 Installation and your first steps with Arpeggio. Installation \u00b6 Arpeggio is written in Python programming language and distributed with setuptools support. If you have pip tool installed the most recent stable version of Arpeggio can be installed form PyPI with the following command: $ pip install Arpeggio To verify that you have installed Arpeggio correctly run the following command: $ python -c 'import arpeggio' If you get no error, Arpeggio is correctly installed. To install Arpeggio for contribution see here . Installing from source \u00b6 If for some weird reason you don't have or don't want to use pip you can still install Arpeggio from source. To download source distribution do: download $ wget https://github.com/textX/Arpeggio/archive/v1.1.tar.gz unpack $ tar xzf v1.1.tar.gz install $ cd Arpeggio-1.1 $ python setup.py install Quick start \u00b6 Basic workflow in using Arpeggio goes like this: Write a grammar . There are several ways to do that: The canonical grammar format uses Python statements and expressions. Each rule is specified as Python function which should return a data structure that defines the rule. For example a grammar for simple calculator can be written as: from arpeggio import Optional, ZeroOrMore, OneOrMore, EOF from arpeggio import RegExMatch as _ def number(): return _(r'\\d*\\.\\d*|\\d+') def factor(): return Optional([\"+\",\"-\"]), [number, (\"(\", expression, \")\")] def term(): return factor, ZeroOrMore([\"*\",\"/\"], factor) def expression(): return term, ZeroOrMore([\"+\", \"-\"], term) def calc(): return OneOrMore(expression), EOF The python lists in the data structure represent ordered choices while the tuples represent sequences from the PEG. For terminal matches use plain strings or regular expressions. The same grammar could also be written using traditional textual PEG syntax like this: number <- r'\\d*\\.\\d*|\\d+'; // this is a comment factor <- (\"+\" / \"-\")? (number / \"(\" expression \")\"); term <- factor (( \"*\" / \"/\") factor)*; expression <- term ((\"+\" / \"-\") term)*; calc <- expression+ EOF; Or similar syntax but a little bit more readable like this: number = r'\\d*\\.\\d*|\\d+' # this is a comment factor = (\"+\" / \"-\")? (number / \"(\" expression \")\") term = factor (( \"*\" / \"/\") factor)* expression = term ((\"+\" / \"-\") term)* calc = expression+ EOF The second and third options are implemented using canonical first form. Feel free to implement your own grammar syntax if you don't like these (see modules arpeggio.peg and arpeggio.cleanpeg ). Instantiate a parser . Parser works as a grammar interpreter. There is no code generation. from arpeggio import ParserPython parser = ParserPython(calc) # calc is the root rule of your grammar # Use param debug=True for verbose debugging # messages and grammar and parse tree visualization # using graphviz and dot Parse your inputs parse_tree = parser.parse(\"-(4-1)*5+(2+4.67)+5.89/(.2+7)\") If parsing is successful (e.g. no syntax error if found) you get a parse tree . Analyze parse tree directly or write a visitor class to transform it to a more usable form. For textual PEG syntaxes instead of ParserPyton instantiate ParserPEG from arpeggio.peg or arpeggio.cleanpeg modules. See examples how it is done. To debug your grammar set debug parameter to True . A verbose debug messages will be printed and a dot files will be generated for parser model (grammar) and parse tree visualization. Here is an image rendered using graphviz of parser model for calc grammar. And here is an image rendered for parse tree for the above parsed calc expression. Read the tutorials \u00b6 Next, you can read some of the step-by-step tutorials ( CSV , BibTex , Calc ). Try the examples \u00b6 Arpeggio comes with a lot of examples . To install and play around with the examples follow the instructions from the README file .","title":"Getting started"},{"location":"getting_started/#getting-started","text":"Installation and your first steps with Arpeggio.","title":"Getting started"},{"location":"getting_started/#installation","text":"Arpeggio is written in Python programming language and distributed with setuptools support. If you have pip tool installed the most recent stable version of Arpeggio can be installed form PyPI with the following command: $ pip install Arpeggio To verify that you have installed Arpeggio correctly run the following command: $ python -c 'import arpeggio' If you get no error, Arpeggio is correctly installed. To install Arpeggio for contribution see here .","title":"Installation"},{"location":"getting_started/#installing-from-source","text":"If for some weird reason you don't have or don't want to use pip you can still install Arpeggio from source. To download source distribution do: download $ wget https://github.com/textX/Arpeggio/archive/v1.1.tar.gz unpack $ tar xzf v1.1.tar.gz install $ cd Arpeggio-1.1 $ python setup.py install","title":"Installing from source"},{"location":"getting_started/#quick-start","text":"Basic workflow in using Arpeggio goes like this: Write a grammar . There are several ways to do that: The canonical grammar format uses Python statements and expressions. Each rule is specified as Python function which should return a data structure that defines the rule. For example a grammar for simple calculator can be written as: from arpeggio import Optional, ZeroOrMore, OneOrMore, EOF from arpeggio import RegExMatch as _ def number(): return _(r'\\d*\\.\\d*|\\d+') def factor(): return Optional([\"+\",\"-\"]), [number, (\"(\", expression, \")\")] def term(): return factor, ZeroOrMore([\"*\",\"/\"], factor) def expression(): return term, ZeroOrMore([\"+\", \"-\"], term) def calc(): return OneOrMore(expression), EOF The python lists in the data structure represent ordered choices while the tuples represent sequences from the PEG. For terminal matches use plain strings or regular expressions. The same grammar could also be written using traditional textual PEG syntax like this: number <- r'\\d*\\.\\d*|\\d+'; // this is a comment factor <- (\"+\" / \"-\")? (number / \"(\" expression \")\"); term <- factor (( \"*\" / \"/\") factor)*; expression <- term ((\"+\" / \"-\") term)*; calc <- expression+ EOF; Or similar syntax but a little bit more readable like this: number = r'\\d*\\.\\d*|\\d+' # this is a comment factor = (\"+\" / \"-\")? (number / \"(\" expression \")\") term = factor (( \"*\" / \"/\") factor)* expression = term ((\"+\" / \"-\") term)* calc = expression+ EOF The second and third options are implemented using canonical first form. Feel free to implement your own grammar syntax if you don't like these (see modules arpeggio.peg and arpeggio.cleanpeg ). Instantiate a parser . Parser works as a grammar interpreter. There is no code generation. from arpeggio import ParserPython parser = ParserPython(calc) # calc is the root rule of your grammar # Use param debug=True for verbose debugging # messages and grammar and parse tree visualization # using graphviz and dot Parse your inputs parse_tree = parser.parse(\"-(4-1)*5+(2+4.67)+5.89/(.2+7)\") If parsing is successful (e.g. no syntax error if found) you get a parse tree . Analyze parse tree directly or write a visitor class to transform it to a more usable form. For textual PEG syntaxes instead of ParserPyton instantiate ParserPEG from arpeggio.peg or arpeggio.cleanpeg modules. See examples how it is done. To debug your grammar set debug parameter to True . A verbose debug messages will be printed and a dot files will be generated for parser model (grammar) and parse tree visualization. Here is an image rendered using graphviz of parser model for calc grammar. And here is an image rendered for parse tree for the above parsed calc expression.","title":"Quick start"},{"location":"getting_started/#read-the-tutorials","text":"Next, you can read some of the step-by-step tutorials ( CSV , BibTex , Calc ).","title":"Read the tutorials"},{"location":"getting_started/#try-the-examples","text":"Arpeggio comes with a lot of examples . To install and play around with the examples follow the instructions from the README file .","title":"Try the examples"},{"location":"grammars/","text":"Grammars \u00b6 With grammar you teach Arpeggio how to parse your inputs. Arpeggio is based on PEG grammars . PEG is a type of formal grammar that is given as a set of rules for recognizing strings of the language. In a way it is similar to context-free grammars with a very important distinction that PEG are always unambiguous. This is achieved by making choice operator ordered. In PEGs a first choice from left to right that matches will be used. Note More information on PEGs can be found on this page . PEG grammar is a set of PEG rules. PEG rules consists of parsing expressions and can reference (call) each other. Example grammar in PEG notation: first = 'foo' second+ EOF second = 'bar' / 'baz' In this example first is the root rule. This rule will match a literal string foo followed by one or more second rule (this is a rule reference) followed by end of input ( EOF ). second rule is ordered choice and will match either bar or baz in that order. Warning Arpeggio requires EOF rule/anchor at the end of the root rule if you want the whole input to be consumed. If you leave out EOF Arpeggio will parse as far as it can, leaving the rest of the input unprocessed, and return without an error. So, be sure to always end your root rule sequence with EOF if you want a complete parse. During parsing each successfully matched rule will create a parse tree node. At the end of parsing a complete parse tree of the input will be returned. In Arpeggio each PEG rule consists of atomic parsing expression which can be: terminal match rules - create a Terminal nodes : String match - a simple string that is matched literally from the input string. RegEx match - regular expression match (based on python re module). non-terminal match rules - create a Non-terminal nodes : Sequence - succeeds if all parsing expressions matches at current location in the defined order. Matched input is consumed. Ordered choice - succeeds if any of the given expressions matches at the current location. The match is tried in the order defined. Matched input is consumed. Zero or more - given expression is matched until match is successful. Always succeeds. Matched input is consumed. One or more - given expressions is matched until match is successful. Succeeds if at least one match is done. Matched input is consumed. Optional - matches given expression but will not fail if match can't be done. Matched input is consumed. Unordered group - matches given expressions in any order. Each given expression must be matched exactly once. Expressions are repeatedly tried from left to right until any succeeds, the process is repeated ignoring already matched expressions, thus the behavior is deterministic. Matched input is consumed. And predicate - succeeds if given expression matches at current location but does not consume any input. Not predicate - succeeds if given expression does not match at current location but does not consume any input. PEG grammars in Arpeggio may be written twofold: Using Python statements and expressions. Using textual PEG syntax (currently there are two variants, see below). Grammars written in Python \u00b6 Canonical form of grammar specification uses Python statements and expressions. Here is an example of arpeggio grammar for simple calculator: def number(): return _(r'\\d*\\.\\d*|\\d+') def factor(): return Optional([\"+\",\"-\"]), [number, (\"(\", expression, \")\")] def term(): return factor, ZeroOrMore([\"*\",\"/\"], factor) def expression(): return term, ZeroOrMore([\"+\", \"-\"], term) def calc(): return OneOrMore(expression), EOF Each rule is given in the form of Python function. Python function returns data structure that maps to PEG expressions. Sequence is represented as Python tuple. Ordered choice is represented as Python list where each element is one alternative. One or more is represented as an instance of OneOrMore class. The parameters are treated as a containing sequence. Zero or more is represented as an instance of ZeroOrMore class. The parameters are treated as a containing sequence. Optional is represented as an instance of Optional class. Unordered group is represented as an instance of UnorderedGroup class. And predicate is represented as an instance of And class. Not predicate is represented as an instance of Not class. Literal string match is represented as string or regular expression given as an instance of RegExMatch class. End of string/file is recognized by the EOF special rule. For example, the calc language consists of one or more expression and end of file. factor rule consists of optional + or - char matched in that order (they are given in Python list thus ordered choice) followed by the ordered choice of number rule and a sequence of expression rule in brackets. This rule will match an optional sign ( + or - tried in that order) after which follows a number or an expression in brackets (tried in that order). From this description Arpeggio builds the parser model . Parser model is a graph of parser expressions (see Grammar visualization ). Each node of the graph is an instance of some of the classes described above which inherits ParserExpression . Parser model construction is done during parser instantiation. For example, to instantiate calc parser you do the following: parser = ParserPython(calc) Where calc is the function defining the root rule of your grammar. There is no code generation. Parser works as an interpreter for your grammar. The grammar is used to configure Arpeggio parser to recognize your language (in this case the calc language). In other words, Arpeggio interprets the parser model (your grammar). After parser construction your can call parser.parse to parse your input text. input_expr = \"-(4-1)*5+(2+4.67)+5.89/(.2+7)\" parse_tree = parser.parse(input_expr) Arpeggio will start from the root node and traverse the parser model graph consuming all matched input. When all root node branches are traversed the parsing is done and the parse tree is returned. You can navigate and analyze parse tree or transform it using visitor pattern to some more usable form (see Semantic analysis - Visitors ) Overriding of special rule classes \u00b6 As we noted above some parsing rules are mapped to Python types ( Sequence to a tuple, OrderedChoice to a list and StrMatch to a string). Sometimes it is useful to override classes that will be instantiated by Arpeggio to provide altered behavior. For example, if we want to suppress all string matches we can register our version of StrMatch which sets suppress to True : class SuppressStrMatch(StrMatch): suppress = True def grammar(): return \"one\", \"two\", RegExMatch(r'\\d+'), \"three\" parser = ParserPython(grammar, syntax_classes={'StrMatch': SuppressStrMatch}) result = parser.parse(\"one two 42 three\") # Only regex will end up in the tree assert len(result) == 1 assert result[0] == \"42\" We use syntax_classes parameter to ParserPython of dict type where keys are names of the original classes and values are our modified class. Now, Arpeggio will instantiate our class whenever it encounters Python string in the grammar. This feature is, obviously, only available for grammars written in Python. Grammars written in PEG notations \u00b6 Grammars can also be specified using PEG notation. There are actually two of them at the moment and both notations are implemented using canonical Python based grammars (see modules arpeggio.peg and arpeggio.cleanpeg ). There are no significant differences between those two syntax. The first one use more traditional approach using <- for rule assignment and ; for the rule terminator. The second syntax (from arpeggio.cleanpeg ) uses = for assignment and does not use rule terminator. Which one you choose is totally up to you. If your don't like any of these syntaxes you can make your own (look at arpeggio.peg and arpeggio.cleanpeg modules as an examples). An example of the calc grammar given in PEG syntax ( arpeggio.cleanpeg ): number = r'\\d*\\.\\d*|\\d+' factor = (\"+\" / \"-\")? (number / \"(\" expression \")\") term = factor (( \"*\" / \"/\") factor)* expression = term ((\"+\" / \"-\") term)* calc = expression+ EOF Each grammar rule is given as an assignment where the LHS is the rule name (e.g. number ) and the RHS is a PEG expression. Literal string matches are given as strings (e.g. \"+\" ). Regex matches are given as strings with prefix r (e.g. r'\\d*\\.\\d*|\\d+' ). Sequence is a space separated list of expressions (e.g. expression+ EOF is a sequence of two expressions). Ordered choice is a list of expression separated with / (e.g. \"+\" / \"-\" ). Optional expression is specified by ? operator (e.g. expression? ) and matches zero or one occurrence of expression Zero or more expression is specified by * operator (e.g. (( \"*\" / \"/\" ) factor)* ). One of more is specified by + operator (e.g. expression+ ). Unordered group is specified by # operator (e.g. sequence# ). It has sense only if applied to the sequence expression. Elements of the sequence are matched in any order. And predicate is specified by & operator (e.g. &expression - not used in the grammar above). Not predicate is specified by ! operator (e.g. !expression - not used in the grammar above). A special rule EOF will match end of input string. In the RHS a rule reference is a name of another rule. Parser will try to match another rule at that location. Literal string matches and regex matches follow the same rules as Python itself would use for single-quoted string literals , regarding the escaping of embedded quotes, and the translation of escape sequences. Literal string matches are treated as normal (non-raw) string literals, and regex matches are treated as raw string literals. Triple-quoting, and the 'r', 'u' and 'b' prefixes, are not supported \u2013 note than in arpeggio PEG grammars, all strings are Unicode, and the 'r' prefix denotes a regular expression. Creating a parser using PEG syntax is done by the class ParserPEG from the arpeggio.peg or arpeggio.cleanpeg modules. from arpeggio.cleanpeg import ParserPEG parser = ParserPEG(calc_grammar, \"calc\") Where calc_grammar is a string with the grammar given above and the \"calc\" is the name of the root rule of the grammar. After this you get the same parser as with the ParserPython . There is no difference at all so you can parse the same language. input_expr = \"-(4-1)*5+(2+4.67)+5.89/(.2+7)\" parse_tree = parser.parse(input_expr) Note Just remember that using textual PEG syntax imposes a slight overhead since the grammar must be parsed and the parser for your language must be built by semantic analysis of grammar parse tree. If you plan to instantiate your parser once and than use it many times this shall not have that much of performance hit but if your workflow introduce instantiating parser each time your parse some input than consider defining your grammar using Python as it will start faster. Nevertheless, the parsing performance will be the same in both approach since the same code for parsing is used.","title":"Grammars"},{"location":"grammars/#grammars","text":"With grammar you teach Arpeggio how to parse your inputs. Arpeggio is based on PEG grammars . PEG is a type of formal grammar that is given as a set of rules for recognizing strings of the language. In a way it is similar to context-free grammars with a very important distinction that PEG are always unambiguous. This is achieved by making choice operator ordered. In PEGs a first choice from left to right that matches will be used. Note More information on PEGs can be found on this page . PEG grammar is a set of PEG rules. PEG rules consists of parsing expressions and can reference (call) each other. Example grammar in PEG notation: first = 'foo' second+ EOF second = 'bar' / 'baz' In this example first is the root rule. This rule will match a literal string foo followed by one or more second rule (this is a rule reference) followed by end of input ( EOF ). second rule is ordered choice and will match either bar or baz in that order. Warning Arpeggio requires EOF rule/anchor at the end of the root rule if you want the whole input to be consumed. If you leave out EOF Arpeggio will parse as far as it can, leaving the rest of the input unprocessed, and return without an error. So, be sure to always end your root rule sequence with EOF if you want a complete parse. During parsing each successfully matched rule will create a parse tree node. At the end of parsing a complete parse tree of the input will be returned. In Arpeggio each PEG rule consists of atomic parsing expression which can be: terminal match rules - create a Terminal nodes : String match - a simple string that is matched literally from the input string. RegEx match - regular expression match (based on python re module). non-terminal match rules - create a Non-terminal nodes : Sequence - succeeds if all parsing expressions matches at current location in the defined order. Matched input is consumed. Ordered choice - succeeds if any of the given expressions matches at the current location. The match is tried in the order defined. Matched input is consumed. Zero or more - given expression is matched until match is successful. Always succeeds. Matched input is consumed. One or more - given expressions is matched until match is successful. Succeeds if at least one match is done. Matched input is consumed. Optional - matches given expression but will not fail if match can't be done. Matched input is consumed. Unordered group - matches given expressions in any order. Each given expression must be matched exactly once. Expressions are repeatedly tried from left to right until any succeeds, the process is repeated ignoring already matched expressions, thus the behavior is deterministic. Matched input is consumed. And predicate - succeeds if given expression matches at current location but does not consume any input. Not predicate - succeeds if given expression does not match at current location but does not consume any input. PEG grammars in Arpeggio may be written twofold: Using Python statements and expressions. Using textual PEG syntax (currently there are two variants, see below).","title":"Grammars"},{"location":"grammars/#grammars-written-in-python","text":"Canonical form of grammar specification uses Python statements and expressions. Here is an example of arpeggio grammar for simple calculator: def number(): return _(r'\\d*\\.\\d*|\\d+') def factor(): return Optional([\"+\",\"-\"]), [number, (\"(\", expression, \")\")] def term(): return factor, ZeroOrMore([\"*\",\"/\"], factor) def expression(): return term, ZeroOrMore([\"+\", \"-\"], term) def calc(): return OneOrMore(expression), EOF Each rule is given in the form of Python function. Python function returns data structure that maps to PEG expressions. Sequence is represented as Python tuple. Ordered choice is represented as Python list where each element is one alternative. One or more is represented as an instance of OneOrMore class. The parameters are treated as a containing sequence. Zero or more is represented as an instance of ZeroOrMore class. The parameters are treated as a containing sequence. Optional is represented as an instance of Optional class. Unordered group is represented as an instance of UnorderedGroup class. And predicate is represented as an instance of And class. Not predicate is represented as an instance of Not class. Literal string match is represented as string or regular expression given as an instance of RegExMatch class. End of string/file is recognized by the EOF special rule. For example, the calc language consists of one or more expression and end of file. factor rule consists of optional + or - char matched in that order (they are given in Python list thus ordered choice) followed by the ordered choice of number rule and a sequence of expression rule in brackets. This rule will match an optional sign ( + or - tried in that order) after which follows a number or an expression in brackets (tried in that order). From this description Arpeggio builds the parser model . Parser model is a graph of parser expressions (see Grammar visualization ). Each node of the graph is an instance of some of the classes described above which inherits ParserExpression . Parser model construction is done during parser instantiation. For example, to instantiate calc parser you do the following: parser = ParserPython(calc) Where calc is the function defining the root rule of your grammar. There is no code generation. Parser works as an interpreter for your grammar. The grammar is used to configure Arpeggio parser to recognize your language (in this case the calc language). In other words, Arpeggio interprets the parser model (your grammar). After parser construction your can call parser.parse to parse your input text. input_expr = \"-(4-1)*5+(2+4.67)+5.89/(.2+7)\" parse_tree = parser.parse(input_expr) Arpeggio will start from the root node and traverse the parser model graph consuming all matched input. When all root node branches are traversed the parsing is done and the parse tree is returned. You can navigate and analyze parse tree or transform it using visitor pattern to some more usable form (see Semantic analysis - Visitors )","title":"Grammars written in Python"},{"location":"grammars/#overriding-of-special-rule-classes","text":"As we noted above some parsing rules are mapped to Python types ( Sequence to a tuple, OrderedChoice to a list and StrMatch to a string). Sometimes it is useful to override classes that will be instantiated by Arpeggio to provide altered behavior. For example, if we want to suppress all string matches we can register our version of StrMatch which sets suppress to True : class SuppressStrMatch(StrMatch): suppress = True def grammar(): return \"one\", \"two\", RegExMatch(r'\\d+'), \"three\" parser = ParserPython(grammar, syntax_classes={'StrMatch': SuppressStrMatch}) result = parser.parse(\"one two 42 three\") # Only regex will end up in the tree assert len(result) == 1 assert result[0] == \"42\" We use syntax_classes parameter to ParserPython of dict type where keys are names of the original classes and values are our modified class. Now, Arpeggio will instantiate our class whenever it encounters Python string in the grammar. This feature is, obviously, only available for grammars written in Python.","title":"Overriding of special rule classes"},{"location":"grammars/#grammars-written-in-peg-notations","text":"Grammars can also be specified using PEG notation. There are actually two of them at the moment and both notations are implemented using canonical Python based grammars (see modules arpeggio.peg and arpeggio.cleanpeg ). There are no significant differences between those two syntax. The first one use more traditional approach using <- for rule assignment and ; for the rule terminator. The second syntax (from arpeggio.cleanpeg ) uses = for assignment and does not use rule terminator. Which one you choose is totally up to you. If your don't like any of these syntaxes you can make your own (look at arpeggio.peg and arpeggio.cleanpeg modules as an examples). An example of the calc grammar given in PEG syntax ( arpeggio.cleanpeg ): number = r'\\d*\\.\\d*|\\d+' factor = (\"+\" / \"-\")? (number / \"(\" expression \")\") term = factor (( \"*\" / \"/\") factor)* expression = term ((\"+\" / \"-\") term)* calc = expression+ EOF Each grammar rule is given as an assignment where the LHS is the rule name (e.g. number ) and the RHS is a PEG expression. Literal string matches are given as strings (e.g. \"+\" ). Regex matches are given as strings with prefix r (e.g. r'\\d*\\.\\d*|\\d+' ). Sequence is a space separated list of expressions (e.g. expression+ EOF is a sequence of two expressions). Ordered choice is a list of expression separated with / (e.g. \"+\" / \"-\" ). Optional expression is specified by ? operator (e.g. expression? ) and matches zero or one occurrence of expression Zero or more expression is specified by * operator (e.g. (( \"*\" / \"/\" ) factor)* ). One of more is specified by + operator (e.g. expression+ ). Unordered group is specified by # operator (e.g. sequence# ). It has sense only if applied to the sequence expression. Elements of the sequence are matched in any order. And predicate is specified by & operator (e.g. &expression - not used in the grammar above). Not predicate is specified by ! operator (e.g. !expression - not used in the grammar above). A special rule EOF will match end of input string. In the RHS a rule reference is a name of another rule. Parser will try to match another rule at that location. Literal string matches and regex matches follow the same rules as Python itself would use for single-quoted string literals , regarding the escaping of embedded quotes, and the translation of escape sequences. Literal string matches are treated as normal (non-raw) string literals, and regex matches are treated as raw string literals. Triple-quoting, and the 'r', 'u' and 'b' prefixes, are not supported \u2013 note than in arpeggio PEG grammars, all strings are Unicode, and the 'r' prefix denotes a regular expression. Creating a parser using PEG syntax is done by the class ParserPEG from the arpeggio.peg or arpeggio.cleanpeg modules. from arpeggio.cleanpeg import ParserPEG parser = ParserPEG(calc_grammar, \"calc\") Where calc_grammar is a string with the grammar given above and the \"calc\" is the name of the root rule of the grammar. After this you get the same parser as with the ParserPython . There is no difference at all so you can parse the same language. input_expr = \"-(4-1)*5+(2+4.67)+5.89/(.2+7)\" parse_tree = parser.parse(input_expr) Note Just remember that using textual PEG syntax imposes a slight overhead since the grammar must be parsed and the parser for your language must be built by semantic analysis of grammar parse tree. If you plan to instantiate your parser once and than use it many times this shall not have that much of performance hit but if your workflow introduce instantiating parser each time your parse some input than consider defining your grammar using Python as it will start faster. Nevertheless, the parsing performance will be the same in both approach since the same code for parsing is used.","title":"Grammars written in PEG notations"},{"location":"handling_errors/","text":"Handling syntax errors in the input \u00b6 This section explains how to handle parsing errors. If your grammar is correct but you get input string with syntax error parser will raise NoMatch exception with the information where in the input stream error has occurred and what the parser expect to see at that location. By default, if NoMatch is not caught you will get detailed explanation of the error at the console. The exact location will be reported, the context (part of the input where the error occurred) and all the rules that were tried at that location. Example: parser = ParserPython(calc) # 'r' in the following expression can't be recognized by # calc grammar input_expr = \"23+4/r-89\" parse_tree = parser.parse(input_expr) As there is an error in the input_expr string ( r is not expected) the following traceback will be printed: Traceback (most recent call last): ... arpeggio.NoMatch: Expected '+' or '-' or 'number' or '(' at position (1, 6) => '23+4/*r-89'. The place in the input stream is marked by * and the position in (line, column) is given ( (1, 6) ). If you wish to handle syntax errors gracefully you can catch NoMatch in your code and inspect its attributes. try: parser = ParserPython(calc) input_expr = \"23+4/r-89\" parse_tree = parser.parse(input_expr) except NoMatch as e: # Do something with e NoMatch class has the following attributes: rules - A list of ParsingExpression rules that are the sources of the exception. position - A position in the input stream where exception occurred. line , col - A line and column in the input stream where exception occurred. parser - A Parser instance used for parsing. Arpeggio is a backtracking parser, which means that it will go back and try another alternatives when the match does not succeeds. Nevertheless, it will report the furthest place in the input where it failed. Arpeggio will report all Match rules that failed at that position.","title":"Handling errors"},{"location":"handling_errors/#handling-syntax-errors-in-the-input","text":"This section explains how to handle parsing errors. If your grammar is correct but you get input string with syntax error parser will raise NoMatch exception with the information where in the input stream error has occurred and what the parser expect to see at that location. By default, if NoMatch is not caught you will get detailed explanation of the error at the console. The exact location will be reported, the context (part of the input where the error occurred) and all the rules that were tried at that location. Example: parser = ParserPython(calc) # 'r' in the following expression can't be recognized by # calc grammar input_expr = \"23+4/r-89\" parse_tree = parser.parse(input_expr) As there is an error in the input_expr string ( r is not expected) the following traceback will be printed: Traceback (most recent call last): ... arpeggio.NoMatch: Expected '+' or '-' or 'number' or '(' at position (1, 6) => '23+4/*r-89'. The place in the input stream is marked by * and the position in (line, column) is given ( (1, 6) ). If you wish to handle syntax errors gracefully you can catch NoMatch in your code and inspect its attributes. try: parser = ParserPython(calc) input_expr = \"23+4/r-89\" parse_tree = parser.parse(input_expr) except NoMatch as e: # Do something with e NoMatch class has the following attributes: rules - A list of ParsingExpression rules that are the sources of the exception. position - A position in the input stream where exception occurred. line , col - A line and column in the input stream where exception occurred. parser - A Parser instance used for parsing. Arpeggio is a backtracking parser, which means that it will go back and try another alternatives when the match does not succeeds. Nevertheless, it will report the furthest place in the input where it failed. Arpeggio will report all Match rules that failed at that position.","title":"Handling syntax errors in the input"},{"location":"parse_trees/","text":"Parse trees \u00b6 Parse tree is a first structure you get from a successful parse. Parse tree or concrete syntax tree is a tree structure built from the input string during parsing. It represent the structure of the input string. Each node in the parse tree is either a terminal or non-terminal . Terminals are the leafs of the tree while the inner nodes are non-terminals. Here is an example parse tree for the calc grammar and the expression -(4-1)*5+(2+4.67)+5.89/(.2+7) : Each non-leaf node is non-terminal. The name in this nodes are the names of the grammar PEG rules that created them. The leaf nodes are terminals and they are matched by the string match or regex match rules. In the square brackets is the location in the input stream where the terminal/non-terminal is recognized. Each parse tree node has the following attributes: rule - the parsing expression that created this node. rule_name - the name of the rule if it was the root rule or empty string otherwise. position - the position in the input stream where this node was recognized. position_end - the end of the node in the input stream. This index is one char behind the last char that belongs to this node. Thus, position_end - position == length of the node . If you want to get line and column from position you can use pos_to_linecol parser method. line, col = parser.pos_to_linecol(node.position) Terminal nodes \u00b6 Terminals in Arpeggio are created by the specializations of the parsing expression Match class. There are two specialization of Match class: StrMatch if the literal string is matched from the input or RegExMatch if a regular expression is used to match input. To get the matched string from the terminal object just convert it to string (e.g. str(t) where t is of Terminal type). Non-terminal nodes \u00b6 Non-terminal nodes are non-leaf nodes of the parse tree. They are created by PEG grammar rules. Children of non-terminals can be other non-terminals or terminals. For example, nodes with the labels expression , factor and term from the above parse tree are non-terminal nodes created by the rules with the same names. NonTerminal inherits from list . The elements of NonTerminal are its children nodes. So, you can use index access: child = pt_node[2] Or iteration: for child in pt_node: ... Additionally, you can access children by the child rule name: For example: # Grammar def foo(): return \"a\", bar, \"b\", baz, \"c\", ZeroOrMore(bar) def bar(): return \"bar\" def baz(): return \"baz\" # Parsing parser = ParserPython(foo) result = parser.parse(\"a bar b baz c bar bar bar\") # Accessing parse tree nodes. All asserts will pass. # Index access assert result[1].rule_name == 'bar' # Access by rule name assert result.bar.rule_name == 'bar' # There are 8 children nodes of the root 'result' node. # Each child is a terminal in this case. assert len(result) == 8 # There is 4 bar matched from result (at the beginning and from ZeroOrMore) # Dot access collect all NTs from the given path assert len(result.bar) == 4 # You could call dot access recursively, e.g. result.bar.baz if the # rule bar called baz. In that case all bars would be collected from # the root and for each bar all baz will be collected. # Verify position # First 'bar' is at position 2 and second is at position 14 assert result.bar[0].position == 2 assert result.bar[1].position == 14 Printing parse trees \u00b6 Elements of the parse tree has tree_str method which can be used to print the tree. For example: ... parse_tree = parser.parse(some_input) print(parse_tree.tree_str()) Result might look something like: simpleLanguage=Sequence [0-191] keyword=Kwd(function) [0-8]: function symbol=RegExMatch(\\w+) [9-12]: fak parameterlist=Sequence [13-20] symbol=RegExMatch(\\w+) [13-14]: n symbol=RegExMatch(\\w+) [16-17]: x symbol=RegExMatch(\\w+) [19-20]: p block=Sequence [22-191] StrMatch({) [22-23]: { statement=Sequence [28-189] ifstatement=Sequence [28-188] keyword=Kwd(if) [28-30]: if StrMatch(() [31-32]: ( expression=OrderedChoice [32-36] operation=Sequence [32-36] symbol=RegExMatch(\\w+) [32-33]: n operator=RegExMatch(\\+|\\-|\\*|\\/|\\=\\=) [33-35]: == literal=RegExMatch(\\d*\\.\\d*|\\d+|\".*?\") [35-36]: 0 StrMatch()) [36-37]: ) block=Sequence [38-93] StrMatch({) [38-39]: { statement=Sequence [78-87] returnstatement=Sequence [78-86] keyword=Kwd(return) [78-84]: return expression=OrderedChoice [85-86] literal=RegExMatch(\\d*\\.\\d*|\\d+|\".*?\") [85-86]: 0 StrMatch(;) [86-87]: ; Each line contains information about the rule and the span of the input where the match occurred. Parse tree reduction \u00b6 Parser can be configured to create a reduced parse tree. More information can be found here . Suppressing parse tree nodes \u00b6 This feature is available for ParserPython only. Rule classes may have a class level suppress attribute set to True . Parse tree nodes produced by these rules will be removed from the resulting parse tree. This may be handy to reduce syntax noise from the punctuation and such in the resulting parse tree. class SuppressStrMatch(StrMatch): suppress = True def grammar(): return \"one\", \"two\", SuppressStrMatch(\"three\"), \"four\" parser = ParserPython(grammar) result = parser.parse(\"one two three four\") assert len(result) == 3 assert result[1] == \"two\" assert result[2] == \"four\" This feature can nicely be combined with overriding of special rule classes .","title":"Parse tree"},{"location":"parse_trees/#parse-trees","text":"Parse tree is a first structure you get from a successful parse. Parse tree or concrete syntax tree is a tree structure built from the input string during parsing. It represent the structure of the input string. Each node in the parse tree is either a terminal or non-terminal . Terminals are the leafs of the tree while the inner nodes are non-terminals. Here is an example parse tree for the calc grammar and the expression -(4-1)*5+(2+4.67)+5.89/(.2+7) : Each non-leaf node is non-terminal. The name in this nodes are the names of the grammar PEG rules that created them. The leaf nodes are terminals and they are matched by the string match or regex match rules. In the square brackets is the location in the input stream where the terminal/non-terminal is recognized. Each parse tree node has the following attributes: rule - the parsing expression that created this node. rule_name - the name of the rule if it was the root rule or empty string otherwise. position - the position in the input stream where this node was recognized. position_end - the end of the node in the input stream. This index is one char behind the last char that belongs to this node. Thus, position_end - position == length of the node . If you want to get line and column from position you can use pos_to_linecol parser method. line, col = parser.pos_to_linecol(node.position)","title":"Parse trees"},{"location":"parse_trees/#terminal-nodes","text":"Terminals in Arpeggio are created by the specializations of the parsing expression Match class. There are two specialization of Match class: StrMatch if the literal string is matched from the input or RegExMatch if a regular expression is used to match input. To get the matched string from the terminal object just convert it to string (e.g. str(t) where t is of Terminal type).","title":"Terminal nodes"},{"location":"parse_trees/#non-terminal-nodes","text":"Non-terminal nodes are non-leaf nodes of the parse tree. They are created by PEG grammar rules. Children of non-terminals can be other non-terminals or terminals. For example, nodes with the labels expression , factor and term from the above parse tree are non-terminal nodes created by the rules with the same names. NonTerminal inherits from list . The elements of NonTerminal are its children nodes. So, you can use index access: child = pt_node[2] Or iteration: for child in pt_node: ... Additionally, you can access children by the child rule name: For example: # Grammar def foo(): return \"a\", bar, \"b\", baz, \"c\", ZeroOrMore(bar) def bar(): return \"bar\" def baz(): return \"baz\" # Parsing parser = ParserPython(foo) result = parser.parse(\"a bar b baz c bar bar bar\") # Accessing parse tree nodes. All asserts will pass. # Index access assert result[1].rule_name == 'bar' # Access by rule name assert result.bar.rule_name == 'bar' # There are 8 children nodes of the root 'result' node. # Each child is a terminal in this case. assert len(result) == 8 # There is 4 bar matched from result (at the beginning and from ZeroOrMore) # Dot access collect all NTs from the given path assert len(result.bar) == 4 # You could call dot access recursively, e.g. result.bar.baz if the # rule bar called baz. In that case all bars would be collected from # the root and for each bar all baz will be collected. # Verify position # First 'bar' is at position 2 and second is at position 14 assert result.bar[0].position == 2 assert result.bar[1].position == 14","title":"Non-terminal nodes"},{"location":"parse_trees/#printing-parse-trees","text":"Elements of the parse tree has tree_str method which can be used to print the tree. For example: ... parse_tree = parser.parse(some_input) print(parse_tree.tree_str()) Result might look something like: simpleLanguage=Sequence [0-191] keyword=Kwd(function) [0-8]: function symbol=RegExMatch(\\w+) [9-12]: fak parameterlist=Sequence [13-20] symbol=RegExMatch(\\w+) [13-14]: n symbol=RegExMatch(\\w+) [16-17]: x symbol=RegExMatch(\\w+) [19-20]: p block=Sequence [22-191] StrMatch({) [22-23]: { statement=Sequence [28-189] ifstatement=Sequence [28-188] keyword=Kwd(if) [28-30]: if StrMatch(() [31-32]: ( expression=OrderedChoice [32-36] operation=Sequence [32-36] symbol=RegExMatch(\\w+) [32-33]: n operator=RegExMatch(\\+|\\-|\\*|\\/|\\=\\=) [33-35]: == literal=RegExMatch(\\d*\\.\\d*|\\d+|\".*?\") [35-36]: 0 StrMatch()) [36-37]: ) block=Sequence [38-93] StrMatch({) [38-39]: { statement=Sequence [78-87] returnstatement=Sequence [78-86] keyword=Kwd(return) [78-84]: return expression=OrderedChoice [85-86] literal=RegExMatch(\\d*\\.\\d*|\\d+|\".*?\") [85-86]: 0 StrMatch(;) [86-87]: ; Each line contains information about the rule and the span of the input where the match occurred.","title":"Printing parse trees"},{"location":"parse_trees/#parse-tree-reduction","text":"Parser can be configured to create a reduced parse tree. More information can be found here .","title":"Parse tree reduction"},{"location":"parse_trees/#suppressing-parse-tree-nodes","text":"This feature is available for ParserPython only. Rule classes may have a class level suppress attribute set to True . Parse tree nodes produced by these rules will be removed from the resulting parse tree. This may be handy to reduce syntax noise from the punctuation and such in the resulting parse tree. class SuppressStrMatch(StrMatch): suppress = True def grammar(): return \"one\", \"two\", SuppressStrMatch(\"three\"), \"four\" parser = ParserPython(grammar) result = parser.parse(\"one two three four\") assert len(result) == 3 assert result[1] == \"two\" assert result[2] == \"four\" This feature can nicely be combined with overriding of special rule classes .","title":"Suppressing parse tree nodes"},{"location":"semantics/","text":"Semantic analysis - Visitors \u00b6 This section explains how to transform parse tree to a more usable structure. You will surely always want to extract some information from the parse tree or to transform it in some more usable form. The process of parse tree transformation to other forms is referred to as semantic analysis . You could do that using parse tree navigation etc., but it is better to use some standard mechanism. In Arpeggio a visitor pattern is used for semantic analysis. You write a python class that inherits PTNodeVisitor and has a methods of the form visit_<rule name>(self, node, children) where rule name is a rule name from the grammar. class CalcVisitor(PTNodeVisitor): def visit_number(self, node, children): return float(node.value) def visit_factor(self, node, children): if len(children) == 1: return children[0] sign = -1 if children[0] == '-' else 1 return sign * children[-1] ... During a semantic analysis a parse tree is walked in the depth-first manner and for each node a proper visitor method is called to transform it to some other form. The results are then fed to the parent node visitor method. This is repeated until the final, top level parse tree node is processed (its visitor is called). The result of the top level node is the final output of the semantic analysis. To run semantic analysis apply your visitor class to the parse tree using visit_parse_tree function. result = visit_parse_tree(parse_tree, CalcVisitor(debug=True)) The first parameter is a parse tree you get from the parser.parse call while the second parameter is an instance of your visitor class. Semantic analysis can be run in debug mode if you set debug parameter to True during visitor construction. You can use this flag to print your own debug information from visitor methods. class MyLanguageVisitor(PTNodeVisitor): def visit_somerule(self, node, children): if self.debug: print(\"Visiting some rule!\") During semantic analysis, each visitor_xxx method gets current parse tree node as the node parameter and the evaluated children nodes as the children parameter. For example, if you have expression rule in your grammar then the transformation of the non-terminal matched by this rule can be done as: def visitor_expression(self, node, children): ... # transform node using 'node' and 'children' parameter return transformed_node node is the current NonTerminal or Terminal from the parse tree while the children is an instance of SemanticActionResults class. This class is a list-like structure that holds the results of semantic evaluation from the children parse tree nodes (analysis is done bottom-up). To suppress node completely return None from visitor method. In this case the parent visitor method will not get this node in its children parameter. In the calc.py example a semantic analysis ( CalcVisitor class) will evaluate the result of arithmetic expression. The parse tree is thus transformed to a single numeric value that represent the result of the expression. In the robot.py example a semantic analysis ( RobotVisitor class) will evaluate robot program (transform its parse tree) to the final robot location. Semantic analysis can do a complex stuff. For example, see peg_peg.py and PEGVisitor class where the PEG parser for the given language is built using semantic analysis. SemanticActionResults \u00b6 SemanticActionResults is the class of object returned from the parse tree nodes evaluation. This class is used for filtering and navigation over evaluation results on children nodes. Instance of this class is given as children parameter of visitor_xxx methods. This class inherits list so index access as well as iteration is available. Furthermore, child nodes can be filtered by rule name using attribute access. def visit_bar(self, node, children): # Index access child = children[2] # Iteration for child in children: ... # Returns a list of all rules created by PEG rule 'baz' baz_created = children.baz Post-processing in second calls \u00b6 Visitor may define method with the second_<rule_name> name form. If this method exists it will be called after all parse tree node are processed and it will be given the results of the visit_<rule_name> call. This is usually used when some additional post-processing is needed (e.g. reference resolving). Default actions \u00b6 For each parse tree node that does not have an appropriate visit_xxx method a default action is performed. If the node is created by a plain string match, action will return None and thus suppress this node. This is handy for all those syntax noise tokens (brackets, braces, keywords etc.). For example, if your grammar is: number_in_brackets = \"(\" number \")\" number = r'\\d+' then the default action for number will return number node converted to a string and the default action for ( and ) will return None and thus suppress these nodes so the visitor method for number_in_brackets rule will only see one child (from the number rule reference). If the node is a non-terminal and there is only one child the default action will return that child effectively passing it to the parent node visitor. Default actions can be disabled by setting parameter defaults to False on visitor construction. result = visit_parse_tree(parse_tree, CalcVisitor(defaults=False)) If you want to call this default behaviour from your visitor method, call visit__default__(node, children) on superclass ( PTNodeVisitor ). def visitor_myrule(self, node, children): if some_condition: ... else: return super(MyVisitor, self).visit__default__(node, children)","title":"Semantic analysis"},{"location":"semantics/#semantic-analysis-visitors","text":"This section explains how to transform parse tree to a more usable structure. You will surely always want to extract some information from the parse tree or to transform it in some more usable form. The process of parse tree transformation to other forms is referred to as semantic analysis . You could do that using parse tree navigation etc., but it is better to use some standard mechanism. In Arpeggio a visitor pattern is used for semantic analysis. You write a python class that inherits PTNodeVisitor and has a methods of the form visit_<rule name>(self, node, children) where rule name is a rule name from the grammar. class CalcVisitor(PTNodeVisitor): def visit_number(self, node, children): return float(node.value) def visit_factor(self, node, children): if len(children) == 1: return children[0] sign = -1 if children[0] == '-' else 1 return sign * children[-1] ... During a semantic analysis a parse tree is walked in the depth-first manner and for each node a proper visitor method is called to transform it to some other form. The results are then fed to the parent node visitor method. This is repeated until the final, top level parse tree node is processed (its visitor is called). The result of the top level node is the final output of the semantic analysis. To run semantic analysis apply your visitor class to the parse tree using visit_parse_tree function. result = visit_parse_tree(parse_tree, CalcVisitor(debug=True)) The first parameter is a parse tree you get from the parser.parse call while the second parameter is an instance of your visitor class. Semantic analysis can be run in debug mode if you set debug parameter to True during visitor construction. You can use this flag to print your own debug information from visitor methods. class MyLanguageVisitor(PTNodeVisitor): def visit_somerule(self, node, children): if self.debug: print(\"Visiting some rule!\") During semantic analysis, each visitor_xxx method gets current parse tree node as the node parameter and the evaluated children nodes as the children parameter. For example, if you have expression rule in your grammar then the transformation of the non-terminal matched by this rule can be done as: def visitor_expression(self, node, children): ... # transform node using 'node' and 'children' parameter return transformed_node node is the current NonTerminal or Terminal from the parse tree while the children is an instance of SemanticActionResults class. This class is a list-like structure that holds the results of semantic evaluation from the children parse tree nodes (analysis is done bottom-up). To suppress node completely return None from visitor method. In this case the parent visitor method will not get this node in its children parameter. In the calc.py example a semantic analysis ( CalcVisitor class) will evaluate the result of arithmetic expression. The parse tree is thus transformed to a single numeric value that represent the result of the expression. In the robot.py example a semantic analysis ( RobotVisitor class) will evaluate robot program (transform its parse tree) to the final robot location. Semantic analysis can do a complex stuff. For example, see peg_peg.py and PEGVisitor class where the PEG parser for the given language is built using semantic analysis.","title":"Semantic analysis - Visitors"},{"location":"semantics/#semanticactionresults","text":"SemanticActionResults is the class of object returned from the parse tree nodes evaluation. This class is used for filtering and navigation over evaluation results on children nodes. Instance of this class is given as children parameter of visitor_xxx methods. This class inherits list so index access as well as iteration is available. Furthermore, child nodes can be filtered by rule name using attribute access. def visit_bar(self, node, children): # Index access child = children[2] # Iteration for child in children: ... # Returns a list of all rules created by PEG rule 'baz' baz_created = children.baz","title":"SemanticActionResults"},{"location":"semantics/#post-processing-in-second-calls","text":"Visitor may define method with the second_<rule_name> name form. If this method exists it will be called after all parse tree node are processed and it will be given the results of the visit_<rule_name> call. This is usually used when some additional post-processing is needed (e.g. reference resolving).","title":"Post-processing in second calls"},{"location":"semantics/#default-actions","text":"For each parse tree node that does not have an appropriate visit_xxx method a default action is performed. If the node is created by a plain string match, action will return None and thus suppress this node. This is handy for all those syntax noise tokens (brackets, braces, keywords etc.). For example, if your grammar is: number_in_brackets = \"(\" number \")\" number = r'\\d+' then the default action for number will return number node converted to a string and the default action for ( and ) will return None and thus suppress these nodes so the visitor method for number_in_brackets rule will only see one child (from the number rule reference). If the node is a non-terminal and there is only one child the default action will return that child effectively passing it to the parent node visitor. Default actions can be disabled by setting parameter defaults to False on visitor construction. result = visit_parse_tree(parse_tree, CalcVisitor(defaults=False)) If you want to call this default behaviour from your visitor method, call visit__default__(node, children) on superclass ( PTNodeVisitor ). def visitor_myrule(self, node, children): if some_condition: ... else: return super(MyVisitor, self).visit__default__(node, children)","title":"Default actions"},{"location":"troubleshooting/","text":"Troubleshooting Guide \u00b6 Common problems and mistakes Left recursion and RecursionError \u00b6 If you get RecursionError: maximum recursion depth exceeded while calling a Python object it is a good indication that you have a left recursion in the grammar. Note Arpeggio parser will implement a support for detecting and reporting of left recursions in the grammar. See issue 23 A left recursion is found if the parser calls the same rule again while no characters from the input is consumed from the previous call (e.g. we have the same state). This will lead to the same sequence of events and we have infinite loop. For example, lets suppose that we want to match following string: b a a a a a a We could write a grammar like this: A = A 'a' / 'b' But this grammar is left-recursive and the recursive-descent top-down parser like Arpeggio will try to loop indefinitely trying to match A over and over again in the same spot of the input string. Although, there are techniques to handle left-recursion in top-down parsers automatically, Arpeggio does not implement them and a classic approach of removing left recursion must be used. To remove left recursion from the above grammar we do the following: A = 'b' 'a'* Or, get all non-left recursive choices and put them first ( b in this case) and than add the zero-or-more repetition of the recursive part without the left recursive non-terminal ( a from A 'a' in this case). Another example: add = mult / add '+' mult / add '-' mult becomes: add = mult (('+' mult) / ('-' mult))* or: add = mult (('+' / '-') mult)* In general: A = A a1 / A a2 / ... / A an / b1 / b2 / ... / bm where uppercase letters represents non-terminals whereas lowercase letters represent terminals. Removing left recursion yields: A = (b1 / b2 / ... / bm) (a1 / a2 / ... / an)* Danger Be aware that the parse tree will not be the same. Unrecognized grammar element '...' \u00b6 This might happen when non-unicode literals are used. Make sure that you use unicode literals when defining grammars using Python notation. You might want to include: from __future__ import unicode_literals This will enable unicode literals in the python < 3. Visitor method is not called during semantic analysis \u00b6 Semantic analysis operates on a parse tree nodes produced by grammar rules. If you are using a reduce_tree=True option in the construction of the parser all non-terminal nodes with only one child will be suppressed in the parse tree. Thus, visitor methods for those nodes will not be called. To resolve issue either disable tree reduction during parser construction (i.e. reduce_tree=False ) or do visitor job in some of the calling rules that produce parse tree node with more than one child. As a side note, there is implicit reduction of nodes whose grammar rule is a sequence with only one child. def mean(): return number def number(): return _(r'\\d*\\.\\d*|\\d+') Here a node number will be suppressed from the parser model and visitor visit_number will not be called. You have to define visit_mean or a visitor for some of the rules calling mean . This implicit reduction can not be disabled at the moment. Please see issue 24 .","title":"Troubleshooting"},{"location":"troubleshooting/#troubleshooting-guide","text":"Common problems and mistakes","title":"Troubleshooting Guide"},{"location":"troubleshooting/#left-recursion-and-recursionerror","text":"If you get RecursionError: maximum recursion depth exceeded while calling a Python object it is a good indication that you have a left recursion in the grammar. Note Arpeggio parser will implement a support for detecting and reporting of left recursions in the grammar. See issue 23 A left recursion is found if the parser calls the same rule again while no characters from the input is consumed from the previous call (e.g. we have the same state). This will lead to the same sequence of events and we have infinite loop. For example, lets suppose that we want to match following string: b a a a a a a We could write a grammar like this: A = A 'a' / 'b' But this grammar is left-recursive and the recursive-descent top-down parser like Arpeggio will try to loop indefinitely trying to match A over and over again in the same spot of the input string. Although, there are techniques to handle left-recursion in top-down parsers automatically, Arpeggio does not implement them and a classic approach of removing left recursion must be used. To remove left recursion from the above grammar we do the following: A = 'b' 'a'* Or, get all non-left recursive choices and put them first ( b in this case) and than add the zero-or-more repetition of the recursive part without the left recursive non-terminal ( a from A 'a' in this case). Another example: add = mult / add '+' mult / add '-' mult becomes: add = mult (('+' mult) / ('-' mult))* or: add = mult (('+' / '-') mult)* In general: A = A a1 / A a2 / ... / A an / b1 / b2 / ... / bm where uppercase letters represents non-terminals whereas lowercase letters represent terminals. Removing left recursion yields: A = (b1 / b2 / ... / bm) (a1 / a2 / ... / an)* Danger Be aware that the parse tree will not be the same.","title":"Left recursion and RecursionError"},{"location":"troubleshooting/#unrecognized-grammar-element","text":"This might happen when non-unicode literals are used. Make sure that you use unicode literals when defining grammars using Python notation. You might want to include: from __future__ import unicode_literals This will enable unicode literals in the python < 3.","title":"Unrecognized grammar element '...'"},{"location":"troubleshooting/#visitor-method-is-not-called-during-semantic-analysis","text":"Semantic analysis operates on a parse tree nodes produced by grammar rules. If you are using a reduce_tree=True option in the construction of the parser all non-terminal nodes with only one child will be suppressed in the parse tree. Thus, visitor methods for those nodes will not be called. To resolve issue either disable tree reduction during parser construction (i.e. reduce_tree=False ) or do visitor job in some of the calling rules that produce parse tree node with more than one child. As a side note, there is implicit reduction of nodes whose grammar rule is a sequence with only one child. def mean(): return number def number(): return _(r'\\d*\\.\\d*|\\d+') Here a node number will be suppressed from the parser model and visitor visit_number will not be called. You have to define visit_mean or a visitor for some of the rules calling mean . This implicit reduction can not be disabled at the moment. Please see issue 24 .","title":"Visitor method is not called during semantic analysis"},{"location":"about/contributing/","text":"Contributions \u00b6 If you want to contribute to the Arpeggio project please see the contribution guide .","title":"Contributing"},{"location":"about/contributing/#contributions","text":"If you want to contribute to the Arpeggio project please see the contribution guide .","title":"Contributions"},{"location":"about/discuss/","text":"Discuss, ask questions \u00b6 If you want to get help or involve in the community. For bug reports, general discussion and help please use GitHub issue tracker .","title":"Discuss"},{"location":"about/discuss/#discuss-ask-questions","text":"If you want to get help or involve in the community. For bug reports, general discussion and help please use GitHub issue tracker .","title":"Discuss, ask questions"},{"location":"about/license/","text":"Arpeggio is released under the terms of the MIT License Copyright (c) 2009-2015 Igor R. Dejanovi\u0107 Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.","title":"License"},{"location":"tutorials/bibtex/","text":"BibTeX tutorial \u00b6 A tutorial for parsing well known format for bibliographic references. The word BibTeX stands for a tool and a file format which are used to describe and process lists of references, mostly in conjunction with LaTeX documents. An example of BibTeX entry is given below. @article{DejanovicADomain-SpecificLanguageforDefiningStaticStructureofDatabaseApplications2010, author = \"Igor Dejanovi\\'{c} and Gordana Milosavljevi\\'{c} and Branko Peri\\v{s}i\\'{c} and Maja Tumbas\", title = \"A {D}omain-Specific Language for Defining Static Structure of Database Applications\", journal = \"Computer Science and Information Systems\", year = \"2010\", volume = \"7\", pages = \"409--440\", number = \"3\", month = \"June\", issn = \"1820-0214\", doi = \"10.2298/CSIS090203002D\", url = \"http://www.comsis.org/ComSIS/Vol7No3/RegularPapers/paper2.htm\", type = \"M23\" } Each BibTeX entry starts with @ and a keyword denoting entry type ( article ) in this example. After the entry type is the body of the reference inside curly braces. The body of the reference consists of elements separated by a comma. The first element is the key of the entry. It should be unique. The rest of the entries are fields in the format: <field_name> = <field_value> The grammar \u00b6 Let's start with the grammar. Create file bibtex.py , and import arpeggio . from arpeggio import * from arpeggio import RegExMatch as _ Then create grammar rules: BibTeX file consists of zero or more BibTeX entries. def bibfile(): return ZeroOrMore(bibentry), EOF Now we define the structure of BibTeX entry. def bibentry(): return bibtype, \"{\", bibkey, \",\", field, ZeroOrMore(\",\", field), \"}\" Each field is given as field name, equals char ( = ), and the field value. def field(): return fieldname, \"=\", fieldvalue Field value can be specified inside braces or quotes. def fieldvalue(): return [fieldvalue_braces, fieldvalue_quotes] def fieldvalue_braces(): return \"{\", fieldvalue_braced_content, \"}\" def fieldvalue_quotes(): return '\"', fieldvalue_quoted_content, '\"' Now, let's define field name, BibTeX type and the key. We use regular expression match for this ( RegExMatch class). def fieldname(): return _(r'[-\\w]+') def bibtype(): return _(r'@\\w+') def bibkey(): return _(r'[^\\s,]+') Field name is defined as hyphen or alphanumeric one or more times. BibTeX entry type is @ char after which must be one or more alphanumeric. BibTeX key is everything until the first space or comma. Field value can be quoted and braced. Let's match the content. def fieldvalue_quoted_content(): return _(r'((\\\\\")|[^\"])*') def fieldvalue_braced_content(): return Combine(ZeroOrMore(Optional(And(\"{\"), fieldvalue_inner),\\ fieldvalue_part)) def fieldvalue_part(): return _(r'((\\\\\")|[^{}])+') def fieldvalue_inner(): return \"{\", fieldvalue_braced_content, \"}\" Combine decorator We use Combine decorator to specify braced content. This decorator produces a Terminal node in the parse tree . The parser \u00b6 To instantiate the parser we are using ParserPython Arpeggio's class. parser = ParserPython(bibfile) Now, we have our parser. Let's parse some input: First load some BibTeX data from a file. file_name = os.path.join(os.path.dirname(__file__), 'bibtex_example.bib') with codecs.open(file_name, \"r\", encoding=\"utf-8\") as bibtexfile: bibtexfile_content = bibtexfile.read() We are using codecs module to load the file using utf-8 encoding. bibtexfile_content is now a string with the content of the file. Parse the input string parse_tree = parser.parse(bibtexfile_content) The parse tree is produced. Extracting data from the parse tree \u00b6 Let's suppose that we want our BibTeX file to be transformed to a list of Python dictionaries where each field is keyed by its name and the value is the field value cleaned up from the BibTeX cruft. Like this: { 'author': 'Igor Dejanovi\u0107 and Gordana Milosavljevi\u0107 and Branko Peri\u0161i\u0107 and Maja Tumbas', 'bibkey': 'DejanovicADomain-SpecificLanguageforDefiningStaticStructureofDatabaseApplications2010', 'bibtype': '@article', 'doi': '10.2298/CSIS090203002D', 'issn': '1820-0214', 'journal': 'Computer Science and Information Systems', 'month': 'June', 'number': '3', 'pages': '409--440', 'title': 'A Domain-Specific Language for Defining Static Structure of Database Applications', 'type': 'M23', 'url': 'http://www.comsis.org/ComSIS/Vol7No3/RegularPapers/paper2.htm', 'volume': '7', 'year': '2010'} The key is stored under a dict key bibkey while the entry type is stored under the dict key bibtype . After calling the parse method on the parser our textual data will be parsed and stored in the parse tree . We could navigate the tree to extract the data and build the python list of dictionaries but a lot easier is to use Arpeggio's visitor support . In this case we shall create BibTeXVisitor class with visit_* methods for each grammar rule whose parse tree node we want to process. class BibTeXVisitor(PTNodeVisitor): def visit_bibfile(self, node, children): \"\"\" Just returns list of child nodes (bibentries). \"\"\" # Return only dict nodes return [x for x in children if type(x) is dict] def visit_bibentry(self, node, children): \"\"\" Constructs a map where key is bibentry field name. Key is returned under 'bibkey' key. Type is returned under 'bibtype'. \"\"\" bib_entry_map = { 'bibtype': children[0], 'bibkey': children[1] } for field in children[2:]: bib_entry_map[field[0]] = field[1] return bib_entry_map def visit_field(self, node, children): \"\"\" Constructs a tuple (fieldname, fieldvalue). \"\"\" field = (children[0], children[1]) return field Now, apply the visitor to the parse tree. ast = visit_parse_tree(parse_tree, BibTeXVisitor()) ast is now a Python list of dictionaries in the desired format from above. A full source code for this example can be found in the source code repository . Note Example in the repository is actually a fully working parser with the support for BibTeX comments and comment entries. This is out of scope for this tutorial. You can find the details in the source code.","title":"BibTex"},{"location":"tutorials/bibtex/#bibtex-tutorial","text":"A tutorial for parsing well known format for bibliographic references. The word BibTeX stands for a tool and a file format which are used to describe and process lists of references, mostly in conjunction with LaTeX documents. An example of BibTeX entry is given below. @article{DejanovicADomain-SpecificLanguageforDefiningStaticStructureofDatabaseApplications2010, author = \"Igor Dejanovi\\'{c} and Gordana Milosavljevi\\'{c} and Branko Peri\\v{s}i\\'{c} and Maja Tumbas\", title = \"A {D}omain-Specific Language for Defining Static Structure of Database Applications\", journal = \"Computer Science and Information Systems\", year = \"2010\", volume = \"7\", pages = \"409--440\", number = \"3\", month = \"June\", issn = \"1820-0214\", doi = \"10.2298/CSIS090203002D\", url = \"http://www.comsis.org/ComSIS/Vol7No3/RegularPapers/paper2.htm\", type = \"M23\" } Each BibTeX entry starts with @ and a keyword denoting entry type ( article ) in this example. After the entry type is the body of the reference inside curly braces. The body of the reference consists of elements separated by a comma. The first element is the key of the entry. It should be unique. The rest of the entries are fields in the format: <field_name> = <field_value>","title":"BibTeX tutorial"},{"location":"tutorials/bibtex/#the-grammar","text":"Let's start with the grammar. Create file bibtex.py , and import arpeggio . from arpeggio import * from arpeggio import RegExMatch as _ Then create grammar rules: BibTeX file consists of zero or more BibTeX entries. def bibfile(): return ZeroOrMore(bibentry), EOF Now we define the structure of BibTeX entry. def bibentry(): return bibtype, \"{\", bibkey, \",\", field, ZeroOrMore(\",\", field), \"}\" Each field is given as field name, equals char ( = ), and the field value. def field(): return fieldname, \"=\", fieldvalue Field value can be specified inside braces or quotes. def fieldvalue(): return [fieldvalue_braces, fieldvalue_quotes] def fieldvalue_braces(): return \"{\", fieldvalue_braced_content, \"}\" def fieldvalue_quotes(): return '\"', fieldvalue_quoted_content, '\"' Now, let's define field name, BibTeX type and the key. We use regular expression match for this ( RegExMatch class). def fieldname(): return _(r'[-\\w]+') def bibtype(): return _(r'@\\w+') def bibkey(): return _(r'[^\\s,]+') Field name is defined as hyphen or alphanumeric one or more times. BibTeX entry type is @ char after which must be one or more alphanumeric. BibTeX key is everything until the first space or comma. Field value can be quoted and braced. Let's match the content. def fieldvalue_quoted_content(): return _(r'((\\\\\")|[^\"])*') def fieldvalue_braced_content(): return Combine(ZeroOrMore(Optional(And(\"{\"), fieldvalue_inner),\\ fieldvalue_part)) def fieldvalue_part(): return _(r'((\\\\\")|[^{}])+') def fieldvalue_inner(): return \"{\", fieldvalue_braced_content, \"}\" Combine decorator We use Combine decorator to specify braced content. This decorator produces a Terminal node in the parse tree .","title":"The grammar"},{"location":"tutorials/bibtex/#the-parser","text":"To instantiate the parser we are using ParserPython Arpeggio's class. parser = ParserPython(bibfile) Now, we have our parser. Let's parse some input: First load some BibTeX data from a file. file_name = os.path.join(os.path.dirname(__file__), 'bibtex_example.bib') with codecs.open(file_name, \"r\", encoding=\"utf-8\") as bibtexfile: bibtexfile_content = bibtexfile.read() We are using codecs module to load the file using utf-8 encoding. bibtexfile_content is now a string with the content of the file. Parse the input string parse_tree = parser.parse(bibtexfile_content) The parse tree is produced.","title":"The parser"},{"location":"tutorials/bibtex/#extracting-data-from-the-parse-tree","text":"Let's suppose that we want our BibTeX file to be transformed to a list of Python dictionaries where each field is keyed by its name and the value is the field value cleaned up from the BibTeX cruft. Like this: { 'author': 'Igor Dejanovi\u0107 and Gordana Milosavljevi\u0107 and Branko Peri\u0161i\u0107 and Maja Tumbas', 'bibkey': 'DejanovicADomain-SpecificLanguageforDefiningStaticStructureofDatabaseApplications2010', 'bibtype': '@article', 'doi': '10.2298/CSIS090203002D', 'issn': '1820-0214', 'journal': 'Computer Science and Information Systems', 'month': 'June', 'number': '3', 'pages': '409--440', 'title': 'A Domain-Specific Language for Defining Static Structure of Database Applications', 'type': 'M23', 'url': 'http://www.comsis.org/ComSIS/Vol7No3/RegularPapers/paper2.htm', 'volume': '7', 'year': '2010'} The key is stored under a dict key bibkey while the entry type is stored under the dict key bibtype . After calling the parse method on the parser our textual data will be parsed and stored in the parse tree . We could navigate the tree to extract the data and build the python list of dictionaries but a lot easier is to use Arpeggio's visitor support . In this case we shall create BibTeXVisitor class with visit_* methods for each grammar rule whose parse tree node we want to process. class BibTeXVisitor(PTNodeVisitor): def visit_bibfile(self, node, children): \"\"\" Just returns list of child nodes (bibentries). \"\"\" # Return only dict nodes return [x for x in children if type(x) is dict] def visit_bibentry(self, node, children): \"\"\" Constructs a map where key is bibentry field name. Key is returned under 'bibkey' key. Type is returned under 'bibtype'. \"\"\" bib_entry_map = { 'bibtype': children[0], 'bibkey': children[1] } for field in children[2:]: bib_entry_map[field[0]] = field[1] return bib_entry_map def visit_field(self, node, children): \"\"\" Constructs a tuple (fieldname, fieldvalue). \"\"\" field = (children[0], children[1]) return field Now, apply the visitor to the parse tree. ast = visit_parse_tree(parse_tree, BibTeXVisitor()) ast is now a Python list of dictionaries in the desired format from above. A full source code for this example can be found in the source code repository . Note Example in the repository is actually a fully working parser with the support for BibTeX comments and comment entries. This is out of scope for this tutorial. You can find the details in the source code.","title":"Extracting data from the parse tree"},{"location":"tutorials/calc/","text":"Calculator tutorial \u00b6 A tutorial for parsing and evaluation of arithmetic expressions. In this tutorial we will make a parser and evaluator for simple arithmetic expression (numbers and operations - addition, subtraction, multiplication and division). The parser will be able to recognize and evaluate following expressions: 2+7-3.6 3/(3-1)+45*2.17+8 4*12+5-4*(2-8) ... Evaluation will be done using support for semantic analysis . Parsing infix expression has additional constraints related to operator precedence. Arpeggio is recursive-descent parser, parsing the input from left to right and doing a leftmost derivation. There is a simple technique that will enable proper evaluation in the context of a different operator precedence. Let's start with grammar definition. The grammar \u00b6 Each calc file consists of one or more expressions. def calc(): return OneOrMore(expression), EOF Each expression is a sum or subtraction of terms. def expression(): return term, ZeroOrMore([\"+\", \"-\"], term) Each term is a multiplication or division of factors. def term(): return factor, ZeroOrMore([\"*\",\"/\"], factor) Note Notice that the order of precedence is from lower to upper. The deeper is the grammar rule, the tighter is the bonding. Each factor is either a number or an expression inside brackets. The prefix sign is optional. This is a support for unary minus. def factor(): return Optional([\"+\",\"-\"]), [number, (\"(\", expression, \")\")] Note Notice indirect recursion here to expression . It is not left since the opening bracket must be found. And finally we define number using regular expression as def number(): return _(r'\\d*\\.\\d*|\\d+') The parser \u00b6 Using above grammar specified in Python notation we instantiate the parser using ParserPython class. parser = ParserPython(calc) This parser is able to parse arithmetic expression like this -(4-1)*5+(2+4.67)+5.89/(.2+7) and produce parse tree like this Note All tree images in this documentation are produced by running the parser in debug mode and using visualization support . The parsing is done like this: input_expr = \"-(4-1)*5+(2+4.67)+5.89/(.2+7)\" parse_tree = parser.parse(input_expr) By ordering operation in the grammar form lower to upper precedence we have got the parse tree where the priority is retained. This will help us to easier make an expression evaluation. Evaluating parse tree \u00b6 To implement evaluation we shall use Arpeggio's support for semantic analysis using visitor patter. Visitor is an object with methods named visit_<rule> which gets called for each node of parse tree produced with the given rule. The processing of the tree nodes is done bottom-up. class CalcVisitor(PTNodeVisitor): def visit_number(self, node, children): \"\"\" Converts node value to float. \"\"\" return float(node.value) ... Visit method for the number rule will do the conversion of the matched text to float type. This nodes will always be the terminal nodes and will be evaluated first. def visit_factor(self, node, children): \"\"\" Applies a sign to the expression or number. \"\"\" if len(children) == 1: return children[0] sign = -1 if children[0] == '-' else 1 return sign * children[-1] Factor will have an optional sign as the first child and whatever matches first from the ordered choice of number and expression. We take the last element. It must be the result of number or expression evaluation and apply an optional sing on it. Note Note that the constant string matches will be removed by the Arpeggio, thus you will never get a constant string match in the children list. def visit_term(self, node, children): \"\"\" Divides or multiplies factors. Factor nodes will be already evaluated. \"\"\" term = children[0] for i in range(2, len(children), 2): if children[i-1] == \"*\": term *= children[i] else: term /= children[i] return term term consist of multiplication or divisions. Both operations are left associative so we shall run from left to right. Each even element will be evaluated factor while each odd element will be an operation to perform. At the end we return the evaluated term . def visit_expression(self, node, children): \"\"\" Adds or subtracts terms. Term nodes will be already evaluated. \"\"\" expr = 0 start = 0 # Check for unary + or - operator if text(children[0]) in \"+-\": start = 1 for i in range(start, len(children), 2): if i and children[i - 1] == \"-\": expr -= children[i] else: expr += children[i] return expr And finally the whole expression consists of additions and subtractions of terms. A minor glitch here is a support for unary minus and plus sign. Let's apply this visitor to our parse tree. result = visit_parse_tree(parse_tree, CalcVisitor(debug=debug)) The result will be a float which represent the value of the given expression. The grammar in PEG \u00b6 As a final note, the same grammar can be specified in textual PEG syntax . Either a clean PEG variant: number = r'\\d*\\.\\d*|\\d+' factor = (\"+\" / \"-\")? (number / \"(\" expression \")\") term = factor (( \"*\" / \"/\") factor)* expression = term ((\"+\" / \"-\") term)* calc = expression+ EOF or traditional PEG variant: number <- r'\\d*\\.\\d*|\\d+'; factor <- (\"+\" / \"-\")? (number / \"(\" expression \")\"); term <- factor (( \"*\" / \"/\") factor)*; expression <- term ((\"+\" / \"-\") term)*; calc <- expression+ EOF; The grammar for textual PEG is parsed using Arpeggio itself and this shows the flexibility of the Arpeggio parser. The code for both parser can be found in the Calc example .","title":"Calc"},{"location":"tutorials/calc/#calculator-tutorial","text":"A tutorial for parsing and evaluation of arithmetic expressions. In this tutorial we will make a parser and evaluator for simple arithmetic expression (numbers and operations - addition, subtraction, multiplication and division). The parser will be able to recognize and evaluate following expressions: 2+7-3.6 3/(3-1)+45*2.17+8 4*12+5-4*(2-8) ... Evaluation will be done using support for semantic analysis . Parsing infix expression has additional constraints related to operator precedence. Arpeggio is recursive-descent parser, parsing the input from left to right and doing a leftmost derivation. There is a simple technique that will enable proper evaluation in the context of a different operator precedence. Let's start with grammar definition.","title":"Calculator tutorial"},{"location":"tutorials/calc/#the-grammar","text":"Each calc file consists of one or more expressions. def calc(): return OneOrMore(expression), EOF Each expression is a sum or subtraction of terms. def expression(): return term, ZeroOrMore([\"+\", \"-\"], term) Each term is a multiplication or division of factors. def term(): return factor, ZeroOrMore([\"*\",\"/\"], factor) Note Notice that the order of precedence is from lower to upper. The deeper is the grammar rule, the tighter is the bonding. Each factor is either a number or an expression inside brackets. The prefix sign is optional. This is a support for unary minus. def factor(): return Optional([\"+\",\"-\"]), [number, (\"(\", expression, \")\")] Note Notice indirect recursion here to expression . It is not left since the opening bracket must be found. And finally we define number using regular expression as def number(): return _(r'\\d*\\.\\d*|\\d+')","title":"The grammar"},{"location":"tutorials/calc/#the-parser","text":"Using above grammar specified in Python notation we instantiate the parser using ParserPython class. parser = ParserPython(calc) This parser is able to parse arithmetic expression like this -(4-1)*5+(2+4.67)+5.89/(.2+7) and produce parse tree like this Note All tree images in this documentation are produced by running the parser in debug mode and using visualization support . The parsing is done like this: input_expr = \"-(4-1)*5+(2+4.67)+5.89/(.2+7)\" parse_tree = parser.parse(input_expr) By ordering operation in the grammar form lower to upper precedence we have got the parse tree where the priority is retained. This will help us to easier make an expression evaluation.","title":"The parser"},{"location":"tutorials/calc/#evaluating-parse-tree","text":"To implement evaluation we shall use Arpeggio's support for semantic analysis using visitor patter. Visitor is an object with methods named visit_<rule> which gets called for each node of parse tree produced with the given rule. The processing of the tree nodes is done bottom-up. class CalcVisitor(PTNodeVisitor): def visit_number(self, node, children): \"\"\" Converts node value to float. \"\"\" return float(node.value) ... Visit method for the number rule will do the conversion of the matched text to float type. This nodes will always be the terminal nodes and will be evaluated first. def visit_factor(self, node, children): \"\"\" Applies a sign to the expression or number. \"\"\" if len(children) == 1: return children[0] sign = -1 if children[0] == '-' else 1 return sign * children[-1] Factor will have an optional sign as the first child and whatever matches first from the ordered choice of number and expression. We take the last element. It must be the result of number or expression evaluation and apply an optional sing on it. Note Note that the constant string matches will be removed by the Arpeggio, thus you will never get a constant string match in the children list. def visit_term(self, node, children): \"\"\" Divides or multiplies factors. Factor nodes will be already evaluated. \"\"\" term = children[0] for i in range(2, len(children), 2): if children[i-1] == \"*\": term *= children[i] else: term /= children[i] return term term consist of multiplication or divisions. Both operations are left associative so we shall run from left to right. Each even element will be evaluated factor while each odd element will be an operation to perform. At the end we return the evaluated term . def visit_expression(self, node, children): \"\"\" Adds or subtracts terms. Term nodes will be already evaluated. \"\"\" expr = 0 start = 0 # Check for unary + or - operator if text(children[0]) in \"+-\": start = 1 for i in range(start, len(children), 2): if i and children[i - 1] == \"-\": expr -= children[i] else: expr += children[i] return expr And finally the whole expression consists of additions and subtractions of terms. A minor glitch here is a support for unary minus and plus sign. Let's apply this visitor to our parse tree. result = visit_parse_tree(parse_tree, CalcVisitor(debug=debug)) The result will be a float which represent the value of the given expression.","title":"Evaluating parse tree"},{"location":"tutorials/calc/#the-grammar-in-peg","text":"As a final note, the same grammar can be specified in textual PEG syntax . Either a clean PEG variant: number = r'\\d*\\.\\d*|\\d+' factor = (\"+\" / \"-\")? (number / \"(\" expression \")\") term = factor (( \"*\" / \"/\") factor)* expression = term ((\"+\" / \"-\") term)* calc = expression+ EOF or traditional PEG variant: number <- r'\\d*\\.\\d*|\\d+'; factor <- (\"+\" / \"-\")? (number / \"(\" expression \")\"); term <- factor (( \"*\" / \"/\") factor)*; expression <- term ((\"+\" / \"-\") term)*; calc <- expression+ EOF; The grammar for textual PEG is parsed using Arpeggio itself and this shows the flexibility of the Arpeggio parser. The code for both parser can be found in the Calc example .","title":"The grammar in PEG"},{"location":"tutorials/csv/","text":"Comma-Separated Values (CSV) parser tutorial \u00b6 A tutorial for building parser for well known CSV format. In this tutorial we will see how to make a parser for a simple data interchange format - CSV (Comma-Separated Values). CSV is a textual format for tabular data interchange. It is described by RFC 4180 . Here is an example of CSV file: Year,Make,Model,Length 1997,Ford,E350,2.34 2000,Mercury,Cougar,2.38 Although, there is csv module in the standard Python library this example has been made as the CSV is ubiquitous and easy to understand so it it a good starter for learning Arpeggio. The grammar \u00b6 Let's start first by creating a python module called csv.py . Now, let's define CSV grammar. CSV file consists of one or more records or newlines and the End-Of-File at the end. Python list inside OneOrMore will be interpreted as Ordered Choice . def csvfile(): return OneOrMore([record, '\\n']), EOF Each record consists of fields separated with commas. def record(): return field, ZeroOrMore(\",\", field) Each field may be quoted or not. def field(): return [quoted_field, field_content] Field content is everything until newline or comma. def field_content(): return _(r'([^,\\n])+') We use regular expression to match everything that is not comma or newline. Quoted field starts and ends with double quotes. def quoted_field(): return '\"', field_content_quoted, '\"' Quoted field content is defined as def field_content_quoted(): return _(r'((\"\")|([^\"]))+') Quoted field content is defined with regular expression that will match everything until the closing double-quote. Double quote inside data must be escaped by doubling it ( \"\" ). The whole content of the csv.py file until now should be: from arpeggio import * from arpeggio import RegExMatch as _ # This is the CSV grammar def record(): return field, ZeroOrMore(\",\", field) def field(): return [quoted_field, field_content] def quoted_field(): return '\"', field_content_quoted, '\"' def field_content(): return _(r'([^,\\n])+') def field_content_quoted(): return _(r'((\"\")|([^\"]))+') def csvfile(): return OneOrMore([record, '\\n']), EOF The parser \u00b6 Let's instantiate parser. In order to catch newlines in csvfile rule we must tell Arpeggio not to treat newlines as whitespace, i.e. not to skip over them. Thus, we will be able to handle them explicitly as we do in csvfile rule. To do so we will use ws parameter in parser construction to redefine what is considered as whitespace. You can find more information here . After the grammar in csv.py instantiate the parser: parser = ParserPython(csvfile, ws='\\t ') So, whitespace will be a tab char or a space. Newline will be treated as regular character. We give grammar root rule to the ParserPython . In this example it is csvfile function. parser now refers to the parser object capable of parsing CSV inputs. Parsing \u00b6 Let's parse some CSV example string. Create file test_data.csv with the following content: Unquoted test, \"Quoted test\", 23234, One Two Three, \"343456.45\" Unquoted test 2, \"Quoted test with \"\"inner\"\" quotes\", 23234, One Two Three, \"34312.7\" Unquoted test 3, \"Quoted test 3\", 23234, One Two Three, \"343486.12\" In csv.py file write: test_data = open('test_data.csv', 'r').read() parse_tree = parser.parse(test_data) test_data is Python string containing test CSV data from the file. Calling parser.parse on the data will produce the parse tree . If you run csv.py module, and there are no syntax errors in the test_data.csv file, parse_tree will be a reference to parse tree of the test CSV data. $ python csv.py Congratulations!! You have successfully parsed CSV file. This parse tree is visualized below (Tip: The image is large. Click on it to see it in a separate tab and to be able to use zooming): Note To visualize grammar (aka parser model) and parse tree instantiate the parser in debug mode. parser = ParserPython(csvfile, ws='\\t ', debug=True) Transform generated dot files to images. See more here Defining grammar using PEG notation \u00b6 Now, let's try the same but using textual PEG notation for the grammar definition. We shall repeat the process above but we shall encode rules in PEG. We shall use clean PEG variant ( arpeggio.cleanpeg module). First, create textual file csv.peg to store the grammar. CSV file consists of one or more records or newlines and the End-Of-File at the end. csvfile = (record / '\\n')+ EOF Each record consists of fields separated with commas. record = field (\",\" field)* Each field may be quoted or not. field = quoted_field / field_content Field content is everything until newline or comma. field_content = r'([^,\\n])+' We use regular expression to match everything that is not comma or newline. Quoted field starts and ends with double quotes. quoted_field = '\"' field_content_quoted '\"' Quoted field content is defined as field_content_quoted = r'((\"\")|([^\"]))+' Quoted field content is defined with regular expression that will match everything until the closing double-quote. Double quote inside data must be escaped by doubling it ( \"\" ). The whole grammar (i.e. the contents of csv.peg file) is: csvfile = (record / r'\\n')+ EOF record = field (\",\" field)* field = quoted_field / field_content field_content = r'([^,\\n])+' quoted_field = '\"' field_content_quoted '\"' field_content_quoted = r'((\"\")|([^\"]))+' Now, we shall create csv_peg.py file in order to instantiate our parser and parse inputs. This time we shall instantiate different parser class ( ParserPEG ). The whole content of csv_peg.py should be: from arpeggio.cleanpeg import ParserPEG csv_grammar = open('csv.peg', 'r').read() parser = ParserPEG(csv_grammar, 'csvfile', ws='\\t ') Here we load the grammar from csv.peg file and construct the parser using ParserPEG class. The rest of the code is the same as in csv.py . We load test_data.csv and call parser.parse on it to produce parse tree. To verify that everything works without errors execute csv_peg.py module. $ python csv_peg.py If we put the parser in debug mode and generate parse tree image we can verify that we are getting the same parse tree regardless of the grammar specification approach we use. To put parser in debug mode add debug=True to the parser parameters list. parser = ParserPEG(csv_grammar, 'csvfile', ws='\\t ', debug=True) Extract data \u00b6 Our main goal is to extract data from the csv file. The parse tree we get as a result of parsing is not very useful on its own. We need to transform it to some other data structure that we can use. First lets define our target data structure we want to get. Since csv consists of list of records where each record consists of fields we shall construct python list of lists: [ [field1, field2, field3, ...], # First row [field1, field2, field3,...], # Second row [...], # ... ... ] To construct this list of list we may process parse tree by navigating its nodes and building the required target data structure. But, it is easier to use Arpeggio's support for semantic analysis - Visitor Pattern . Let's make a Visitor for CSV that will build our list of lists. class CSVVisitor(PTNodeVisitor): def visit_record(self, node, children): # record is a list of fields. The children nodes are fields so just # transform it to python list. return list(children) def visit_csvfile(self, node, children): # We are not interested in empty lines so we will filter them. return [x for x in children if x!='\\n'] and apply this visitor to the parse tree: csv_content = visit_parse_tree(parse_tree, CSVVisitor()) Now if we pretty-print csv_content we can see that it is exactly what we wanted: [ [ u'Unquoted test', u'Quoted test', u'23234', u'One Two Three', u'343456.45'], [ u'Unquoted test 2', u'Quoted test with \"\"inner\"\" quotes', u'23234', u'One Two Three', u'34312.7'], [ u'Unquoted test 3', u'Quoted test 3', u'23234', u'One Two Three', u'343486.12']] But, there is more we can do. If we look at our data we can see that some fields are of numeric type but they end up as strings in our target structure. Let's convert them to Python floats or ints. To do this conversion we will introduce visit_field method in our CSVVisitor class. class CSVVisitor(PTNodeVisitor): ... def visit_field(self, node, children): value = children[0] try: return float(value) except: pass try: return int(value) except: return value ... If we pretty-print csv_content now we can see that numeric values are not strings anymore but a proper Python types. [ [u'Unquoted test', u'Quoted test', 23234.0, u'One Two Three', 343456.45], [ u'Unquoted test 2', u'Quoted test with \"\"inner\"\" quotes', 23234.0, u'One Two Three', 34312.7], [ u'Unquoted test 3', u'Quoted test 3', 23234.0, u'One Two Three', 343486.12]] This example code can be found here .","title":"CSV"},{"location":"tutorials/csv/#comma-separated-values-csv-parser-tutorial","text":"A tutorial for building parser for well known CSV format. In this tutorial we will see how to make a parser for a simple data interchange format - CSV (Comma-Separated Values). CSV is a textual format for tabular data interchange. It is described by RFC 4180 . Here is an example of CSV file: Year,Make,Model,Length 1997,Ford,E350,2.34 2000,Mercury,Cougar,2.38 Although, there is csv module in the standard Python library this example has been made as the CSV is ubiquitous and easy to understand so it it a good starter for learning Arpeggio.","title":"Comma-Separated Values (CSV) parser tutorial"},{"location":"tutorials/csv/#the-grammar","text":"Let's start first by creating a python module called csv.py . Now, let's define CSV grammar. CSV file consists of one or more records or newlines and the End-Of-File at the end. Python list inside OneOrMore will be interpreted as Ordered Choice . def csvfile(): return OneOrMore([record, '\\n']), EOF Each record consists of fields separated with commas. def record(): return field, ZeroOrMore(\",\", field) Each field may be quoted or not. def field(): return [quoted_field, field_content] Field content is everything until newline or comma. def field_content(): return _(r'([^,\\n])+') We use regular expression to match everything that is not comma or newline. Quoted field starts and ends with double quotes. def quoted_field(): return '\"', field_content_quoted, '\"' Quoted field content is defined as def field_content_quoted(): return _(r'((\"\")|([^\"]))+') Quoted field content is defined with regular expression that will match everything until the closing double-quote. Double quote inside data must be escaped by doubling it ( \"\" ). The whole content of the csv.py file until now should be: from arpeggio import * from arpeggio import RegExMatch as _ # This is the CSV grammar def record(): return field, ZeroOrMore(\",\", field) def field(): return [quoted_field, field_content] def quoted_field(): return '\"', field_content_quoted, '\"' def field_content(): return _(r'([^,\\n])+') def field_content_quoted(): return _(r'((\"\")|([^\"]))+') def csvfile(): return OneOrMore([record, '\\n']), EOF","title":"The grammar"},{"location":"tutorials/csv/#the-parser","text":"Let's instantiate parser. In order to catch newlines in csvfile rule we must tell Arpeggio not to treat newlines as whitespace, i.e. not to skip over them. Thus, we will be able to handle them explicitly as we do in csvfile rule. To do so we will use ws parameter in parser construction to redefine what is considered as whitespace. You can find more information here . After the grammar in csv.py instantiate the parser: parser = ParserPython(csvfile, ws='\\t ') So, whitespace will be a tab char or a space. Newline will be treated as regular character. We give grammar root rule to the ParserPython . In this example it is csvfile function. parser now refers to the parser object capable of parsing CSV inputs.","title":"The parser"},{"location":"tutorials/csv/#parsing","text":"Let's parse some CSV example string. Create file test_data.csv with the following content: Unquoted test, \"Quoted test\", 23234, One Two Three, \"343456.45\" Unquoted test 2, \"Quoted test with \"\"inner\"\" quotes\", 23234, One Two Three, \"34312.7\" Unquoted test 3, \"Quoted test 3\", 23234, One Two Three, \"343486.12\" In csv.py file write: test_data = open('test_data.csv', 'r').read() parse_tree = parser.parse(test_data) test_data is Python string containing test CSV data from the file. Calling parser.parse on the data will produce the parse tree . If you run csv.py module, and there are no syntax errors in the test_data.csv file, parse_tree will be a reference to parse tree of the test CSV data. $ python csv.py Congratulations!! You have successfully parsed CSV file. This parse tree is visualized below (Tip: The image is large. Click on it to see it in a separate tab and to be able to use zooming): Note To visualize grammar (aka parser model) and parse tree instantiate the parser in debug mode. parser = ParserPython(csvfile, ws='\\t ', debug=True) Transform generated dot files to images. See more here","title":"Parsing"},{"location":"tutorials/csv/#defining-grammar-using-peg-notation","text":"Now, let's try the same but using textual PEG notation for the grammar definition. We shall repeat the process above but we shall encode rules in PEG. We shall use clean PEG variant ( arpeggio.cleanpeg module). First, create textual file csv.peg to store the grammar. CSV file consists of one or more records or newlines and the End-Of-File at the end. csvfile = (record / '\\n')+ EOF Each record consists of fields separated with commas. record = field (\",\" field)* Each field may be quoted or not. field = quoted_field / field_content Field content is everything until newline or comma. field_content = r'([^,\\n])+' We use regular expression to match everything that is not comma or newline. Quoted field starts and ends with double quotes. quoted_field = '\"' field_content_quoted '\"' Quoted field content is defined as field_content_quoted = r'((\"\")|([^\"]))+' Quoted field content is defined with regular expression that will match everything until the closing double-quote. Double quote inside data must be escaped by doubling it ( \"\" ). The whole grammar (i.e. the contents of csv.peg file) is: csvfile = (record / r'\\n')+ EOF record = field (\",\" field)* field = quoted_field / field_content field_content = r'([^,\\n])+' quoted_field = '\"' field_content_quoted '\"' field_content_quoted = r'((\"\")|([^\"]))+' Now, we shall create csv_peg.py file in order to instantiate our parser and parse inputs. This time we shall instantiate different parser class ( ParserPEG ). The whole content of csv_peg.py should be: from arpeggio.cleanpeg import ParserPEG csv_grammar = open('csv.peg', 'r').read() parser = ParserPEG(csv_grammar, 'csvfile', ws='\\t ') Here we load the grammar from csv.peg file and construct the parser using ParserPEG class. The rest of the code is the same as in csv.py . We load test_data.csv and call parser.parse on it to produce parse tree. To verify that everything works without errors execute csv_peg.py module. $ python csv_peg.py If we put the parser in debug mode and generate parse tree image we can verify that we are getting the same parse tree regardless of the grammar specification approach we use. To put parser in debug mode add debug=True to the parser parameters list. parser = ParserPEG(csv_grammar, 'csvfile', ws='\\t ', debug=True)","title":"Defining grammar using PEG notation"},{"location":"tutorials/csv/#extract-data","text":"Our main goal is to extract data from the csv file. The parse tree we get as a result of parsing is not very useful on its own. We need to transform it to some other data structure that we can use. First lets define our target data structure we want to get. Since csv consists of list of records where each record consists of fields we shall construct python list of lists: [ [field1, field2, field3, ...], # First row [field1, field2, field3,...], # Second row [...], # ... ... ] To construct this list of list we may process parse tree by navigating its nodes and building the required target data structure. But, it is easier to use Arpeggio's support for semantic analysis - Visitor Pattern . Let's make a Visitor for CSV that will build our list of lists. class CSVVisitor(PTNodeVisitor): def visit_record(self, node, children): # record is a list of fields. The children nodes are fields so just # transform it to python list. return list(children) def visit_csvfile(self, node, children): # We are not interested in empty lines so we will filter them. return [x for x in children if x!='\\n'] and apply this visitor to the parse tree: csv_content = visit_parse_tree(parse_tree, CSVVisitor()) Now if we pretty-print csv_content we can see that it is exactly what we wanted: [ [ u'Unquoted test', u'Quoted test', u'23234', u'One Two Three', u'343456.45'], [ u'Unquoted test 2', u'Quoted test with \"\"inner\"\" quotes', u'23234', u'One Two Three', u'34312.7'], [ u'Unquoted test 3', u'Quoted test 3', u'23234', u'One Two Three', u'343486.12']] But, there is more we can do. If we look at our data we can see that some fields are of numeric type but they end up as strings in our target structure. Let's convert them to Python floats or ints. To do this conversion we will introduce visit_field method in our CSVVisitor class. class CSVVisitor(PTNodeVisitor): ... def visit_field(self, node, children): value = children[0] try: return float(value) except: pass try: return int(value) except: return value ... If we pretty-print csv_content now we can see that numeric values are not strings anymore but a proper Python types. [ [u'Unquoted test', u'Quoted test', 23234.0, u'One Two Three', 343456.45], [ u'Unquoted test 2', u'Quoted test with \"\"inner\"\" quotes', 23234.0, u'One Two Three', 34312.7], [ u'Unquoted test 3', u'Quoted test 3', 23234.0, u'One Two Three', 343486.12]] This example code can be found here .","title":"Extract data"}]}